{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5158126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d29ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import io\n",
    "import awswrangler as wr\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import s3_input, Session\n",
    "import pickle\n",
    "\n",
    "\n",
    "import constants as params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fa2931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns_types(df_cols, y_name):\n",
    "    \n",
    "    ind_cols = list(df_cols[df_cols.str.contains('_ind')])\n",
    "    pmpm_cols =  list(df_cols[df_cols.str.contains('_pmpm_')])\n",
    "    score_cols = list(df_cols[df_cols.str.contains('_score')])\n",
    "\n",
    "    categorical_cols = ind_cols + [y_name]\n",
    "    numerical_cols = pmpm_cols + score_cols\n",
    "    ordinal_cols = []\n",
    "    return (categorical_cols, numerical_cols, ordinal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "479ad12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type_conversion(df, categorical_cols, numerical_cols):\n",
    "    df[numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    df[categorical_cols] = df[categorical_cols].astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25fab9",
   "metadata": {},
   "source": [
    "#### Creating summation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "092a17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_feature_generation(df, categories, categorical_cols, numerical_cols):\n",
    "    for category in categories:\n",
    "        new_ind_name = category + \"_ind_sum\"\n",
    "        subset_cols_criteria = \"_\" + category + \"_\"\n",
    "        subset_cols = [x for x in df.columns if subset_cols_criteria in x and '_ind' in x]\n",
    "        df[new_ind_name] = df[subset_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "        df[subset_cols] = df[subset_cols].astype(\"category\")\n",
    "        df[new_ind_name] = df[new_ind_name].astype(\"category\")\n",
    "        numerical_cols.append(new_ind_name)\n",
    "        \n",
    "\n",
    "        new_pmpm_name = category + \"_pmpm_sum\"\n",
    "        subset_cols_criteria = \"_\" + category + \"_\"\n",
    "        subset_cols = [x for x in df.columns if subset_cols_criteria in x and '_pmpm' in x]\n",
    "\n",
    "        df[new_pmpm_name] = df[subset_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "        numerical_cols.append(new_pmpm_name)\n",
    "#         df = add_columns(df=df, col_name=new_ind_name, columns= subset_cols)\n",
    "    return (df_subset, categorical_cols, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cbb3a8",
   "metadata": {},
   "source": [
    "#### creating a final column to have the count of number of services used by each person using ind values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d123ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_features(df, numerical_cols, categorical_cols):\n",
    "    df['total_ind'] = df[df.columns[df.columns.str.contains('_ind_sum')]].sum(axis=1)\n",
    "    df['total_ind'] = df['total_ind'].apply(pd.to_numeric, errors = 'coerce')\n",
    "    numerical_cols.append('total_ind')\n",
    "    \n",
    "    df['total_pmpm'] = df[df.columns[df.columns.str.contains('_pmpm_sum')]].sum(axis=1)\n",
    "    df['total_pmpm'] = df['total_pmpm'].apply(pd.to_numeric, errors = 'coerce')\n",
    "    numerical_cols.append('total_pmpm')\n",
    "\n",
    "    df['service_bool'] = np.where(df['total_ind'] == 0, 0, 1)\n",
    "    df['service_bool'] = df['service_bool'].astype(\"category\")\n",
    "    categorical_cols.append('service_bool')\n",
    "    return df, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1faca41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To create a new bucket\n",
    "# bucket_name = 'bucket-name55422' # new bucket_name\n",
    "# my_region = boto3.session.Session().region_name\n",
    "\n",
    "# s3 = boto3.resource('s3')\n",
    "# try:\n",
    "#     if my_region == \"us-east-1\":\n",
    "#         s3.create_bucket(Bucket = bucket_name)\n",
    "#         print('S3 bucket created successfully')\n",
    "# except Exception as e:\n",
    "#     print('S3 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac748fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"humana-data\"\n",
    "prefix = 'rawdata/original_pq_files'\n",
    "prefix_data = \"intermediate/condition/data\"\n",
    "prefix_metadata = \"intermediate/condition/models/metadata\"\n",
    "prefix_model = \"intermediate/condition/models\"\n",
    "\n",
    "\n",
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket, Prefix=prefix)['Contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "790873ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13101/2500392804.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_pmpm_name] = df[subset_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
      "/tmp/ipykernel_13101/2500392804.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_ind_name] = df[subset_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
      "/tmp/ipykernel_13101/289015400.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['total_ind'] = df[df.columns[df.columns.str.contains('_ind_sum')]].sum(axis=1)\n",
      "/tmp/ipykernel_13101/289015400.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['service_bool'] = np.where(df['total_ind'] == 0, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "condition_file = \"Condition.pq\"\n",
    "dependent_file = \"dependent.pq\"\n",
    "\n",
    "condition_df = wr.s3.read_parquet(path = f's3://{bucket}/{prefix}/{condition_file}')\n",
    "condition_df = condition_df.set_index(['person_id_syn'])\n",
    "condition_df.columns = condition_df.columns.str.lower()\n",
    "\n",
    "dependent_df = wr.s3.read_parquet(path = f's3://{bucket}/{prefix}/{dependent_file}')\n",
    "dependent_df = dependent_df.set_index(['person_id_syn'])\n",
    "dependent_df['transportation_issues'] = dependent_df['transportation_issues'].astype(\"category\")\n",
    "dependent_df.columns = dependent_df.columns.str.lower()\n",
    "\n",
    "df_subset = dependent_df.merge(condition_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "categorical_cols, numerical_cols, ordinal_cols = create_columns_types(df_cols = df_subset.columns,\n",
    "                                                                      y_name = params.dependent_variable)\n",
    "\n",
    "df_subset[categorical_cols] = np.where(df_subset[categorical_cols] != 0, 1,0)\n",
    "\n",
    "df_subset, categorical_cols, numerical_cols = sum_feature_generation(df_subset, params.categories, \n",
    "                                              categorical_cols =categorical_cols,\n",
    "                                             numerical_cols = numerical_cols)\n",
    "\n",
    "df_subset, numerical_cols, categorical_cols = total_sum_features(df = df_subset, \n",
    "                                                                 numerical_cols=numerical_cols, \n",
    "                                                                 categorical_cols=categorical_cols)\n",
    "\n",
    "\n",
    "df_subset = data_type_conversion(df=df_subset, \n",
    "                                 categorical_cols=categorical_cols, \n",
    "                                 numerical_cols=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ab7982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_subset.sample(frac=0.7, random_state=543)\n",
    "valid_df = df_subset[~(df_subset.index.isin(train_df.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35dcdd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://humana-data/intermediate/condition/data/valid_fe.pq'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_train ='train_fe.pq'\n",
    "filename_valid ='valid_fe.pq'\n",
    "\n",
    "wr.s3.to_parquet(train_df, path = f's3://{bucket}/{prefix_data}/{filename_train}', compression='gzip', index=True)\n",
    "wr.s3.to_parquet(valid_df, path = f's3://{bucket}/{prefix_data}/{filename_valid}', compression='gzip', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5992d",
   "metadata": {},
   "source": [
    "#### Build XgBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fb67ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train ='train_fe.pq'\n",
    "filename_valid ='valid_fe.pq'\n",
    "\n",
    "train_df = wr.s3.read_parquet(path = f's3://{bucket}/{prefix_data}/{filename_train}')\n",
    "valid_df = wr.s3.read_parquet(path = f's3://{bucket}/{prefix_data}/{filename_valid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "387393b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# one hot encoding\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown=\"ignore\" )\n",
    "one_hot_encode_cols = [x for x in categorical_cols if x != params.dependent_variable]\n",
    "train_df_encoded = pd.DataFrame(enc.fit_transform(train_df[one_hot_encode_cols]), index=train_df.index)\n",
    "train_df_encoded.columns = enc.get_feature_names_out()\n",
    "\n",
    "train_model_df = pd.concat([train_df.drop(one_hot_encode_cols, axis=1), train_df_encoded], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4d020ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoded categorical model\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "\n",
    "filename_encoder ='enc.pkl'\n",
    "path = prefix_model + '/' + filename_encoder\n",
    "\n",
    "# WRITE\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    joblib.dump(enc, fp)\n",
    "    fp.seek(0)\n",
    "    conn.put_object(Body=fp.read(), Bucket=bucket, Key=path)\n",
    "\n",
    "# READ\n",
    "# with tempfile.TemporaryFile() as fp:\n",
    "#     conn.download_fileobj(Fileobj=fp, Bucket=bucket, Key=path)\n",
    "#     fp.seek(0)\n",
    "#     enc2 = joblib.load(fp)\n",
    "\n",
    "# # DELETE\n",
    "# conn.delete_object(Bucket=bucket, Key=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfee9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_encoded = pd.DataFrame(enc.transform(valid_df[one_hot_encode_cols]), index=valid_df.index)\n",
    "valid_df_encoded.columns = enc.get_feature_names_out()\n",
    "valid_model_df = pd.concat([valid_df.drop(one_hot_encode_cols, axis=1), valid_df_encoded], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "373d7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write the metadata of index\n",
    "# train_id_index = train_model_df.reset_index()[\"person_id_syn\"]\n",
    "# train_id_index = train_id_index.reset_index().rename(columns={'index':'index_num'})\n",
    "# filename_train_id_index = \"train_index_id.pq\"\n",
    "# wr.s3.to_parquet(train_id_index, path = 's3://{}/{}/{}'.format(bucket, prefix_metadata, filename_train_id_index),\n",
    "#                  compression='gzip', index=False)\n",
    "\n",
    "\n",
    "# valid_id_index = valid_model_df.reset_index()[\"person_id_syn\"]\n",
    "# valid_id_index = valid_id_index.reset_index().rename(columns={'index':'index_num'})\n",
    "# filename_valid_id_index = \"valid_index_id.pq\"\n",
    "# wr.s3.to_parquet(valid_id_index, path = 's3://{}/{}/{}'.format(bucket, prefix_metadata, filename_valid_id_index),\n",
    "#                  compression='gzip', index=False)\n",
    "\n",
    "\n",
    "# # Write the metadata of columns\n",
    "# train_model_columns = train_model_df.columns\n",
    "# test_model_columns = [x for x in train_model_columns if x != params.dependent_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a97e5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'BF0JN46KWCB3FCXN',\n",
       "  'HostId': '+5G7zi7mTkJWk0HT7kdoX929ATxAczLGnxU/XcJAGHJxCl527WnUSnBpBwGJuxAppYy2hE7pONw=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '+5G7zi7mTkJWk0HT7kdoX929ATxAczLGnxU/XcJAGHJxCl527WnUSnBpBwGJuxAppYy2hE7pONw=',\n",
       "   'x-amz-request-id': 'BF0JN46KWCB3FCXN',\n",
       "   'date': 'Fri, 11 Nov 2022 21:07:14 GMT',\n",
       "   'x-amz-version-id': 'AI3fnePi0dg6f5ZaaPtWmVa_UaX2sT4I',\n",
       "   'etag': '\"c47ce33b1e1a100b81e5f57a530bd737\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"c47ce33b1e1a100b81e5f57a530bd737\"',\n",
       " 'VersionId': 'AI3fnePi0dg6f5ZaaPtWmVa_UaX2sT4I'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the metadata of columns, index of train and valid and test\n",
    "filename_metadata = prefix_metadata + '/' + 'metadata_dict'\n",
    "\n",
    "metadata_dict = {}\n",
    "metadata_dict['train_index'] = dict(zip(list(train_model_df.reset_index()['person_id_syn'].index), train_model_df.reset_index()['person_id_syn']))\n",
    "metadata_dict['valid_index'] = dict(zip(list(valid_model_df.reset_index()['person_id_syn'].index), valid_model_df.reset_index()['person_id_syn']))\n",
    "metadata_dict['train_columns'] = list(train_model_df.columns)\n",
    "metadata_dict['test_columns'] = [x for x in train_model_df.columns if x != params.dependent_variable]\n",
    "metadata_dict['categorical_cols'] = [x for x in categorical_cols if x != params.dependent_variable]\n",
    "metadata_dict['numerical_cols'] = numerical_cols.copy()\n",
    "\n",
    "\n",
    "conn.put_object(Bucket=bucket, Key=filename_metadata, Body=pickle.dumps(metadata_dict))\n",
    "\n",
    "\n",
    "# # to read the file\n",
    "# metadata_dict = conn.get_object(Bucket=bucket, Key=filename_metadata)\n",
    "# serializedObject = metadata_dict['Body'].read()\n",
    "# metadata_dict = pickle.loads(serializedObject)\n",
    "# metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c926751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "prefix_data = \"intermediate/condition/data\"\n",
    "filename_train_model ='train_model.csv'\n",
    "filename_valid_model ='valid_model.csv'\n",
    "\n",
    "bytes_to_write = train_model_df.to_csv(index=False, header=False).encode()\n",
    "fs = s3fs.S3FileSystem()\n",
    "with fs.open('s3://{}/{}/{}'.format(bucket, prefix_data, filename_train_model), 'wb') as f:\n",
    "    f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = valid_model_df.to_csv(index=False, header=False).encode()\n",
    "fs = s3fs.S3FileSystem()\n",
    "with fs.open('s3://{}/{}/{}'.format(bucket, prefix_data, filename_valid_model), 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ada20a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_data = \"intermediate/condition/data\"\n",
    "filename_train_model ='train_model.csv'\n",
    "filename_valid_model ='valid_model.csv'\n",
    "\n",
    "## Specifies the path to training and validation in S3\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/{}'.format(bucket, prefix_data, filename_train_model), content_type='csv')\n",
    "s3_input_valid = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/{}'.format(bucket, prefix_data, filename_valid_model), content_type='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f12bc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58c0401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intermediate/condition/models'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73a59160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/intermediate/condition/models/xgboost-condition-data/output'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_model = \"intermediate/condition/models/xgboost-condition-data\"\n",
    "output_path  = 's3://{}/{}/output'.format(bucket, prefix_model)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8de6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0546dde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(region_name, 'xgboost', 'latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ecc70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"num_round\":100,\n",
    "    \"max_depth\":8,\n",
    "    \"eta\":0.2,\n",
    "    \"gamma\": 3,\n",
    "    \"objective\":\"binary:logistic\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a24398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                         hyperparameters = hyperparameters,\n",
    "                                         role = sagemaker.get_execution_role(),\n",
    "                                         instance_count = 1,\n",
    "                                         instance_type = 'ml.m5.large',\n",
    "                                         volume_size = 5,\n",
    "                                         output_path = output_path,\n",
    "                                         use_spot_instances = True,\n",
    "                                          max_run = 300,\n",
    "                                          max_wait = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c778103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-11 20:32:41 Starting - Starting the training job...\n",
      "2022-11-11 20:33:05 Starting - Preparing the instances for trainingProfilerReport-1668198760: InProgress\n",
      "............\n",
      "2022-11-11 20:35:05 Downloading - Downloading input data...\n",
      "2022-11-11 20:35:38 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-11-11:20:35:43:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-11-11:20:35:43:INFO] File size need to be processed in the node: 190.78mb. Available memory size in the node: 383.48mb\u001b[0m\n",
      "\u001b[34m[2022-11-11:20:35:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:35:43] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[20:35:44] 48700x669 matrix with 32580300 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-11-11:20:35:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:35:44] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[20:35:44] 20872x669 matrix with 13963368 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[20:35:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 300 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.137598#011validation-error:0.152022\u001b[0m\n",
      "\u001b[34m[20:35:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 296 extra nodes, 34 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.136078#011validation-error:0.148812\u001b[0m\n",
      "\u001b[34m[20:35:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 274 extra nodes, 34 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.136386#011validation-error:0.147806\u001b[0m\n",
      "\u001b[34m[20:35:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 298 extra nodes, 46 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.135647#011validation-error:0.147901\u001b[0m\n",
      "\u001b[34m[20:35:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 258 extra nodes, 50 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.135483#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:35:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 266 extra nodes, 54 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.136016#011validation-error:0.147901\u001b[0m\n",
      "\u001b[34m[20:35:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 284 extra nodes, 32 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.135873#011validation-error:0.147614\u001b[0m\n",
      "\u001b[34m[20:35:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 302 extra nodes, 34 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.135072#011validation-error:0.147806\u001b[0m\n",
      "\u001b[34m[20:35:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 280 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.134497#011validation-error:0.147614\u001b[0m\n",
      "\u001b[34m[20:35:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 278 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.13386#011validation-error:0.147566\u001b[0m\n",
      "\u001b[34m[20:36:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 318 extra nodes, 30 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.133388#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:36:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 280 extra nodes, 34 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.13271#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:36:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 320 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.131725#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 262 extra nodes, 40 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.131027#011validation-error:0.146943\u001b[0m\n",
      "\u001b[34m[20:36:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 274 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.130144#011validation-error:0.146464\u001b[0m\n",
      "\u001b[34m[20:36:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 186 extra nodes, 44 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.129856#011validation-error:0.146704\u001b[0m\n",
      "\u001b[34m[20:36:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 272 extra nodes, 50 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.128706#011validation-error:0.1468\u001b[0m\n",
      "\u001b[34m[20:36:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.128357#011validation-error:0.146895\u001b[0m\n",
      "\u001b[34m[20:36:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 178 extra nodes, 50 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.128049#011validation-error:0.146704\u001b[0m\n",
      "\u001b[34m[20:36:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 52 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.126632#011validation-error:0.146177\u001b[0m\n",
      "\u001b[34m[20:36:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 204 extra nodes, 66 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.125565#011validation-error:0.146177\u001b[0m\n",
      "\u001b[34m[20:36:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 192 extra nodes, 60 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.124784#011validation-error:0.146273\u001b[0m\n",
      "\u001b[34m[20:36:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 156 extra nodes, 40 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.124127#011validation-error:0.146225\u001b[0m\n",
      "\u001b[34m[20:36:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 16 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.123593#011validation-error:0.146368\u001b[0m\n",
      "\u001b[34m[20:36:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 164 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.123101#011validation-error:0.146464\u001b[0m\n",
      "\u001b[34m[20:36:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 52 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.121643#011validation-error:0.14656\u001b[0m\n",
      "\u001b[34m[20:36:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 40 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.121006#011validation-error:0.14656\u001b[0m\n",
      "\u001b[34m[20:36:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 146 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.120287#011validation-error:0.146847\u001b[0m\n",
      "\u001b[34m[20:36:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.120021#011validation-error:0.1468\u001b[0m\n",
      "\u001b[34m[20:36:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 170 extra nodes, 74 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.119117#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:36:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 146 extra nodes, 46 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.118624#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 136 extra nodes, 34 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.118296#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 30 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.117906#011validation-error:0.147518\u001b[0m\n",
      "\u001b[34m[20:36:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.117248#011validation-error:0.14747\u001b[0m\n",
      "\u001b[34m[20:36:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 30 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.117105#011validation-error:0.147327\u001b[0m\n",
      "\u001b[34m[20:36:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 290 extra nodes, 70 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.115791#011validation-error:0.147614\u001b[0m\n",
      "\u001b[34m[20:36:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 184 extra nodes, 86 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.114969#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:36:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 30 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.114579#011validation-error:0.147039\u001b[0m\n",
      "\u001b[34m[20:36:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 46 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.114394#011validation-error:0.146991\u001b[0m\n",
      "\u001b[34m[20:36:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 132 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.113984#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 6 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.113429#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 196 extra nodes, 94 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.112752#011validation-error:0.147327\u001b[0m\n",
      "\u001b[34m[20:36:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 144 extra nodes, 96 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.112485#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:36:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 12 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.112238#011validation-error:0.147135\u001b[0m\n",
      "\u001b[34m[20:36:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 44 pruned nodes, max_depth=8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[44]#011train-error:0.111766#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:36:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 36 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.111622#011validation-error:0.14747\u001b[0m\n",
      "\u001b[34m[20:36:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 186 extra nodes, 70 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.110842#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 214 extra nodes, 92 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.109836#011validation-error:0.147422\u001b[0m\n",
      "\u001b[34m[20:36:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 162 extra nodes, 80 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.10924#011validation-error:0.146991\u001b[0m\n",
      "\u001b[34m[20:36:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 70 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.108727#011validation-error:0.146943\u001b[0m\n",
      "\u001b[34m[20:36:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 34 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.108439#011validation-error:0.146991\u001b[0m\n",
      "\u001b[34m[20:36:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 200 extra nodes, 78 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.107166#011validation-error:0.147135\u001b[0m\n",
      "\u001b[34m[20:36:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 274 extra nodes, 80 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.106263#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 66 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.105688#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:36:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 174 extra nodes, 98 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.104969#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:36:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 68 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.104949#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:36:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 22 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.104805#011validation-error:0.147039\u001b[0m\n",
      "\u001b[34m[20:36:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 50 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.104456#011validation-error:0.147087\u001b[0m\n",
      "\u001b[34m[20:37:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 54 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.104374#011validation-error:0.147135\u001b[0m\n",
      "\u001b[34m[20:37:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 80 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.104107#011validation-error:0.147087\u001b[0m\n",
      "\u001b[34m[20:37:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.103881#011validation-error:0.147183\u001b[0m\n",
      "\u001b[34m[20:37:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 168 extra nodes, 74 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.10308#011validation-error:0.147231\u001b[0m\n",
      "\u001b[34m[20:37:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 98 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.103039#011validation-error:0.14747\u001b[0m\n",
      "\u001b[34m[20:37:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 26 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:37:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\u001b[34m[20:37:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.102895#011validation-error:0.147374\u001b[0m\n",
      "\n",
      "2022-11-11 20:38:09 Uploading - Uploading generated training model\n",
      "2022-11-11 20:38:09 Completed - Training job completed\n",
      "Training seconds: 203\n",
      "Billable seconds: 88\n",
      "Managed Spot Training savings: 56.7%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':s3_input_train, 'validation':s3_input_valid})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240afbf",
   "metadata": {},
   "source": [
    "### Deploy ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fd77208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "xgb_condition_predictor = estimator.deploy(initial_instance_count = 1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f23ae4",
   "metadata": {},
   "source": [
    "### Predicts on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed3634a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_array = valid_model_df.drop(columns= ['transportation_issues']).values\n",
    "# xgb_condition_predictor.content_type = 'text/csv'\n",
    "# xgb_condition_predictor.serializer = csv_serializer\n",
    "predictions = xgb_condition_predictor.predict(valid_data_array).decode('utf-8')\n",
    "prdictions_array = np.fromstring(predictions[1:], sep=',')\n",
    "print(predictions_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a9b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480b30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3774b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbaf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
