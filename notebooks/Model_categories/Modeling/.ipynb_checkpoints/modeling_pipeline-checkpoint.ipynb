{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6b7c5c",
   "metadata": {},
   "source": [
    "### Import the saved preprocessor and encoder.\n",
    "Apply on the train dataset and then build an XgBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48b4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3480a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'humana-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64003a7",
   "metadata": {},
   "source": [
    "### Preprocessing the data (same for train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24411ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/rawdata/original_raw_files/train'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = 's3://{}/rawdata/original_raw_files/train'.format(bucket)\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a9de30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/rawdata/original_raw_files/valid'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input = 's3://{}/rawdata/original_raw_files/valid'.format(bucket)\n",
    "valid_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7bad67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/rawdata/original_raw_files/test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = 's3://{}/rawdata/original_raw_files/test'.format(bucket)\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56673a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "# FRAMEWORK_VERSION = \"1.0-1\"\n",
    "# script_dir = \"humana_script\"\n",
    "# script_path = \"humana_preprocessing.py\"\n",
    "\n",
    "# script_dependent_dir = script_dir + '/' + 'humana_package/'\n",
    "# script_dependent_dir\n",
    "\n",
    "# sklearn_train_processor = SKLearnProcessor(\n",
    "#     framework_version=FRAMEWORK_VERSION,\n",
    "#     role=role, instance_type=\"ml.c4.xlarge\", instance_count=1\n",
    "# )\n",
    "\n",
    "# from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# sklearn_train_processor.run(code = script_dir + '/' + script_path,\n",
    "#                      inputs = [ProcessingInput(source = train_input, destination = \"/opt/ml/processing/input\"),\n",
    "#                               ProcessingInput(source = script_dependent_dir, \n",
    "#                                               destination = \"/opt/ml/processing/input/code/humana_package/\")\n",
    "#                               ],\n",
    "#                      outputs = [ProcessingOutput(output_name = \"df_fe\", source = \"/opt/ml/processing/train\"),\n",
    "#                                ],\n",
    "#                       arguments = ['--train_or_valid_or_test', \"train\"],\n",
    "#                      )\n",
    "\n",
    "# preprocessing_job_description = sklearn_train_processor.jobs[-1].describe()\n",
    "\n",
    "# output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "\n",
    "# for output in output_config[\"Outputs\"]:\n",
    "#     if output[\"OutputName\"] == \"df_fe\":\n",
    "#         preprocessed_train_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "# preprocessed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813f3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_data = 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-29-02-14-28-105/output/df_fe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e394d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "# FRAMEWORK_VERSION = \"1.0-1\"\n",
    "# script_dir = \"humana_script\"\n",
    "# script_path = \"humana_preprocessing.py\"\n",
    "\n",
    "# script_dependent_dir = script_dir + '/' + 'humana_package/'\n",
    "# script_dependent_dir\n",
    "\n",
    "# sklearn_valid_processor = SKLearnProcessor(\n",
    "#     framework_version=FRAMEWORK_VERSION,\n",
    "#     role=role, instance_type=\"ml.c4.xlarge\", instance_count=1\n",
    "# )\n",
    "\n",
    "# from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# sklearn_valid_processor.run(code = script_dir + '/' + script_path,\n",
    "#                      inputs = [ProcessingInput(source = valid_input, destination = \"/opt/ml/processing/input\"),\n",
    "#                               ProcessingInput(source = script_dependent_dir, \n",
    "#                                               destination = \"/opt/ml/processing/input/code/humana_package/\")\n",
    "#                               ],\n",
    "#                      outputs = [ProcessingOutput(output_name = \"df_fe\", source = \"/opt/ml/processing/valid\"),\n",
    "#                                ],\n",
    "#                       arguments = ['--train_or_valid_or_test', \"valid\"],\n",
    "#                      )\n",
    "\n",
    "# preprocessing_job_description = sklearn_valid_processor.jobs[-1].describe()\n",
    "\n",
    "# output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "\n",
    "# for output in output_config[\"Outputs\"]:\n",
    "#     if output[\"OutputName\"] == \"df_fe\":\n",
    "#         preprocessed_valid_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "# preprocessed_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a10bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_valid_data = 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-29-03-37-05-637/output/df_fe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fddf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f15967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# ff = pd.read_csv(preprocessed_valid_data + \"/df_fe_valid.csv\")\n",
    "# ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528afe6",
   "metadata": {},
   "source": [
    "### Encoding the train data (with a model created and saved earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humana_script/humana_package/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dir = \"humana_script\"\n",
    "script_path = \"humana_preprocessing.py\"\n",
    "script_dependent_dir = script_dir + '/' + 'humana_package/'\n",
    "script_dependent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ce2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encoder\n",
    "# import sagemaker\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# FRAMEWORK_VERSION = \"1.0-1\"\n",
    "# script_path = \"humana_encoder.py\"\n",
    "# script_dir = \"humana_script\"\n",
    "\n",
    "# sklearn_encoder = SKLearn(\n",
    "#     entry_point= script_path,\n",
    "#     source_dir = script_dependent_dir,\n",
    "#     role=role,\n",
    "#     framework_version=FRAMEWORK_VERSION,\n",
    "#     instance_type=\"ml.c4.xlarge\",\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "# )\n",
    "\n",
    "# print(\"entry_point\", script_dir +\"/\" + script_path)\n",
    "# print(script_dependent_dir)\n",
    "# sklearn_encoder.fit({\"train\": preprocessed_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c6fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "# transformer = sklearn_encoder.transformer(\n",
    "#     instance_count=1, instance_type=\"ml.c4.xlarge\", assemble_with=\"Line\", accept=\"text/csv\"\n",
    "# )\n",
    "# # Preprocess training input\n",
    "# transformer.transform(preprocessed_train_data, content_type=\"text/csv\")\n",
    "# print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "# transformer.wait()\n",
    "# encoded_train = transformer.output_path\n",
    "# encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e1925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b13cdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-scikit-learn-2022-12-29-03-45-32-528-something\n"
     ]
    }
   ],
   "source": [
    "script_path = \"humana_encoder.py\"\n",
    "script_dir = \"humana_script\"\n",
    "\n",
    "\n",
    "# import saved sklearn encoder and perform transformation on train dataset\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "sklearn_encoder_saved = sess.create_model_from_job(\n",
    "    training_job_name = \"sagemaker-scikit-learn-2022-12-29-03-45-32-528\", \n",
    "    name=\"{}-something\".format(\"sagemaker-scikit-learn-2022-12-29-03-45-32-528\"),\n",
    "    role=role,\n",
    "    env={\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\", \n",
    "     \"SAGEMAKER_USE_NGINX\": \"True\", \n",
    "     \"SAGEMAKER_WORKER_CLASS_TYPE\": \"gevent\", \n",
    "     \"SAGEMAKER_KEEP_ALIVE_SEC\": \"60\", \n",
    "     \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "     \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": \"false\",\n",
    "     \"SAGEMAKER_PROGRAM\": \"humana_encoder.py\", #the entry point present in training-src-files.tar.gz\n",
    "     \"SAGEMAKER_REGION\": \"us-east-1\",\n",
    "     \"SAGEMAKER_SUBMIT_DIRECTORY\": \"s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-29-03-45-32-528/source/sourcedir.tar.gz\",\n",
    "    }\n",
    ")\n",
    "\n",
    "transformer_saved = Transformer(\n",
    "    sklearn_encoder_saved,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.c4.xlarge\",\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# # Preprocess training input\n",
    "# transformer_saved.transform(preprocessed_train_data, content_type=\"text/csv\")\n",
    "\n",
    "# print(\"Waiting for transform job: \" + transformer_saved.latest_transform_job.job_name)\n",
    "# transformer_saved.wait()\n",
    "# encoded_train_data = transformer_saved.output_path\n",
    "# encoded_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d23f1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-29-03-53-04-601'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1072d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6222211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess training input\n",
    "# transformer_saved.transform(preprocessed_valid_data, content_type=\"text/csv\")\n",
    "\n",
    "# print(\"Waiting for transform job: \" + transformer_saved.latest_transform_job.job_name)\n",
    "# transformer_saved.wait()\n",
    "# encoded_valid_data = transformer_saved.output_path\n",
    "# encoded_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a60a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid = 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-29-04-01-45-228'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "089f957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = \"s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5f4c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region = us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the role we have created for our notebook here:\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "sm = boto3.Session().client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39cc5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep, gmtime, strftime\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65ca6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import SageMaker Experiments\n",
    "\n",
    "# from sagemaker.analytics import ExperimentAnalytics\n",
    "# from smexperiments.experiment import Experiment\n",
    "# from smexperiments.trial import Trial\n",
    "# from smexperiments.trial_component import TrialComponent\n",
    "# from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c40309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09810577",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3275fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# container = sagemaker.image_uris.retrieve(\"xgboost\", sess.boto_region_name, \"1.5-1\")\n",
    "# display(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5492ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.inputs import TrainingInput\n",
    "# from sagemaker.xgboost.estimator import XGBoost\n",
    "# s3_input_train = TrainingInput(\n",
    "#     s3_data=encoded_train, content_type=\"csv\"\n",
    "# )\n",
    "# s3_input_validation = TrainingInput(\n",
    "#     s3_data=encoded_valid, content_type=\"csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b5c5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humana-data'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ab37642",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'xgboost_v6' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6a7d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "}\n",
    "\n",
    "instance_type = \"ml.c4.xlarge\"\n",
    "output_path = \"s3://{}/{}/{}/output\".format(bucket, prefix, \"abalone-dist-xgb\")\n",
    "content_type = \"csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d367184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/xgboost_v6/abalone-dist-xgb/output'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "875644b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Source distributed script mode\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "session = Session()\n",
    "script_path = \"humana_script/humana_model_train.py\"\n",
    "\n",
    "xgb_script_mode_estimator = XGBoost(\n",
    "    entry_point=script_path,\n",
    "    framework_version=\"1.5-1\",  # Note: framework_version is mandatory\n",
    "    hyperparameters=hyperparams,\n",
    "    role=role,\n",
    "    instance_count=2,\n",
    "    instance_type=instance_type,\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    encoded_train, content_type=content_type\n",
    ")\n",
    "validation_input = TrainingInput(\n",
    "    encoded_valid, content_type=content_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3e67f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-30 18:15:50 Starting - Starting the training job...\n",
      "2022-12-30 18:16:14 Starting - Preparing the instances for trainingProfilerReport-1672424149: InProgress\n",
      ".........\n",
      "2022-12-30 18:17:50 Downloading - Downloading input data......\n",
      "2022-12-30 18:18:35 Training - Training image download completed. Training in progress.\u001b[34m[2022-12-30 18:18:35.768 ip-10-2-128-254.ec2.internal:6 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:35:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:35:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:36:INFO] Module humana_model_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:36:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:36:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:36:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=7588 sha256=56a199c95560f430570d3ea828b0873a3bed9aa9ac5fff0364e78b2c53fa55aa\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-mk1mrabp/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-model-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:18:37:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"gamma\": \"4\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"num_round\": \"50\",\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"subsample\": \"0.7\",\n",
      "        \"verbosity\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2022-12-30-18-15-49-712\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://humana-data/sagemaker-xgboost-2022-12-30-18-15-49-712/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"humana_model_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"humana_model_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"binary:logistic\",\"subsample\":\"0.7\",\"verbosity\":\"2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=humana_model_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=humana_model_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://humana-data/sagemaker-xgboost-2022-12-30-18-15-49-712/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"binary:logistic\",\"subsample\":\"0.7\",\"verbosity\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-12-30-18-15-49-712\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://humana-data/sagemaker-xgboost-2022-12-30-18-15-49-712/source/sourcedir.tar.gz\",\"module_name\":\"humana_model_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"humana_model_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"binary:logistic\",\"--subsample\",\"0.7\",\"--verbosity\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=50\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSITY=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m humana_model_train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective binary:logistic --subsample 0.7 --verbosity 2\u001b[0m\n",
      "\u001b[35m[2022-12-30 18:18:35.592 ip-10-2-185-51.ec2.internal:8 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] Module humana_model_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:35:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=7588 sha256=b219342504876a9e546ffee099c88ee9f082b029141cbc1fa846eea36a4b9f48\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-ivtptrkh/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humana-model-train\u001b[0m\n",
      "\u001b[35mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:18:37:INFO] Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"gamma\": \"4\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"num_round\": \"50\",\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"subsample\": \"0.7\",\n",
      "        \"verbosity\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"sagemaker-xgboost-2022-12-30-18-15-49-712\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://humana-data/sagemaker-xgboost-2022-12-30-18-15-49-712/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"humana_model_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"humana_model_train.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"binary:logistic\",\"subsample\":\"0.7\",\"verbosity\":\"2\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=humana_model_train.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=humana_model_train\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://humana-data/sagemaker-xgboost-2022-12-30-18-15-49-712/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"binary:logistic\",\"subsample\":\"0.7\",\"verbosity\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"sagemaker-xgboost-2022-12-30-18-15-49-712\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://humana-data/sagemaker-xgboost-2022-12-30-18-15-49-712/source/sourcedir.tar.gz\",\"module_name\":\"humana_model_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"humana_model_train.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"binary:logistic\",\"--subsample\",\"0.7\",\"--verbosity\",\"2\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[35mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[35mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[35mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[35mSM_HP_NUM_ROUND=50\u001b[0m\n",
      "\u001b[35mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[35mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[35mSM_HP_VERBOSITY=2\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m humana_model_train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective binary:logistic --subsample 0.7 --verbosity 2\u001b[0m\n",
      "\u001b[34m[18:18:41] task NULL got new rank 0\u001b[0m\n",
      "\u001b[35m[18:18:41] task NULL got new rank 1\u001b[0m\n",
      "\u001b[35m[18:18:45] task NULL got new rank 1\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] task NULL got new rank 0\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[18:18:45] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:45] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:46] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:47] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:48] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[18:18:49] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-12-30 18:19:15 Uploading - Uploading generated training model\n",
      "2022-12-30 18:19:15 Completed - Training job completed\n",
      "Training seconds: 156\n",
      "Billable seconds: 156\n"
     ]
    }
   ],
   "source": [
    "xgb_script_mode_estimator.fit({\"train\": train_input, \"validation\": validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3315ec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da1c0870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    599\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out', header=None)\n",
    "test_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4ec943a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>589</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "      <th>596</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.850762</td>\n",
       "      <td>-0.888748</td>\n",
       "      <td>-0.763909</td>\n",
       "      <td>-0.748104</td>\n",
       "      <td>-0.406172</td>\n",
       "      <td>-0.428499</td>\n",
       "      <td>-0.225091</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.786963</td>\n",
       "      <td>-0.342490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.979032</td>\n",
       "      <td>0.136183</td>\n",
       "      <td>-0.676484</td>\n",
       "      <td>-1.078982</td>\n",
       "      <td>-0.754293</td>\n",
       "      <td>-0.763548</td>\n",
       "      <td>-1.199974</td>\n",
       "      <td>-0.473057</td>\n",
       "      <td>-0.754925</td>\n",
       "      <td>-0.402556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.666340</td>\n",
       "      <td>-0.674113</td>\n",
       "      <td>1.650295</td>\n",
       "      <td>-0.323727</td>\n",
       "      <td>-0.968105</td>\n",
       "      <td>-0.588225</td>\n",
       "      <td>-0.592834</td>\n",
       "      <td>-0.449931</td>\n",
       "      <td>-1.106484</td>\n",
       "      <td>-0.899804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820003</td>\n",
       "      <td>-0.610405</td>\n",
       "      <td>0.344865</td>\n",
       "      <td>-0.653065</td>\n",
       "      <td>0.662634</td>\n",
       "      <td>1.523682</td>\n",
       "      <td>0.541741</td>\n",
       "      <td>-1.461354</td>\n",
       "      <td>-1.254163</td>\n",
       "      <td>-1.396181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.334072</td>\n",
       "      <td>-0.122851</td>\n",
       "      <td>-0.672897</td>\n",
       "      <td>-0.895831</td>\n",
       "      <td>-0.943124</td>\n",
       "      <td>0.471593</td>\n",
       "      <td>-0.266845</td>\n",
       "      <td>-0.081502</td>\n",
       "      <td>-1.237243</td>\n",
       "      <td>-0.549077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.668196</td>\n",
       "      <td>0.500191</td>\n",
       "      <td>-0.789244</td>\n",
       "      <td>0.078716</td>\n",
       "      <td>1.354221</td>\n",
       "      <td>0.560906</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>-0.504134</td>\n",
       "      <td>1.274838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.500826</td>\n",
       "      <td>-0.080353</td>\n",
       "      <td>-0.401910</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>1.924781</td>\n",
       "      <td>3.446114</td>\n",
       "      <td>0.857242</td>\n",
       "      <td>-0.648715</td>\n",
       "      <td>0.376440</td>\n",
       "      <td>1.471037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>1.965204</td>\n",
       "      <td>0.658449</td>\n",
       "      <td>0.453569</td>\n",
       "      <td>1.310276</td>\n",
       "      <td>-0.635707</td>\n",
       "      <td>-0.722282</td>\n",
       "      <td>-0.521186</td>\n",
       "      <td>2.510745</td>\n",
       "      <td>0.707052</td>\n",
       "      <td>-0.247112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.092057</td>\n",
       "      <td>0.143028</td>\n",
       "      <td>-0.352185</td>\n",
       "      <td>-0.041459</td>\n",
       "      <td>-0.631626</td>\n",
       "      <td>-0.865170</td>\n",
       "      <td>-0.950898</td>\n",
       "      <td>-0.068284</td>\n",
       "      <td>-1.183397</td>\n",
       "      <td>-0.042836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>-0.487613</td>\n",
       "      <td>-0.562571</td>\n",
       "      <td>-0.358210</td>\n",
       "      <td>-0.827335</td>\n",
       "      <td>-0.044090</td>\n",
       "      <td>-0.143293</td>\n",
       "      <td>-0.526979</td>\n",
       "      <td>0.297353</td>\n",
       "      <td>-0.266681</td>\n",
       "      <td>-0.582529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.850762 -0.888748 -0.763909 -0.748104 -0.406172 -0.428499 -0.225091   \n",
       "1    -0.979032  0.136183 -0.676484 -1.078982 -0.754293 -0.763548 -1.199974   \n",
       "2    -0.666340 -0.674113  1.650295 -0.323727 -0.968105 -0.588225 -0.592834   \n",
       "3    -0.820003 -0.610405  0.344865 -0.653065  0.662634  1.523682  0.541741   \n",
       "4    -0.334072 -0.122851 -0.672897 -0.895831 -0.943124  0.471593 -0.266845   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2995  0.668196  0.500191 -0.789244  0.078716  1.354221  0.560906  0.426910   \n",
       "2996  0.500826 -0.080353 -0.401910  0.082491  1.924781  3.446114  0.857242   \n",
       "2997  1.965204  0.658449  0.453569  1.310276 -0.635707 -0.722282 -0.521186   \n",
       "2998  0.092057  0.143028 -0.352185 -0.041459 -0.631626 -0.865170 -0.950898   \n",
       "2999 -0.487613 -0.562571 -0.358210 -0.827335 -0.044090 -0.143293 -0.526979   \n",
       "\n",
       "           7         8         9    ...  589  590  591  592  593  594  595  \\\n",
       "0    -0.025857 -0.786963 -0.342490  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    -0.473057 -0.754925 -0.402556  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2    -0.449931 -1.106484 -0.899804  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3    -1.461354 -1.254163 -1.396181  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4    -0.081502 -1.237243 -0.549077  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2995  0.542986 -0.504134  1.274838  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2996 -0.648715  0.376440  1.471037  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2997  2.510745  0.707052 -0.247112  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2998 -0.068284 -1.183397 -0.042836  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2999  0.297353 -0.266681 -0.582529  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      596  597  598  \n",
       "0     0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  \n",
       "...   ...  ...  ...  \n",
       "2995  0.0  0.0  0.0  \n",
       "2996  0.0  0.0  0.0  \n",
       "2997  0.0  0.0  0.0  \n",
       "2998  0.0  0.0  0.0  \n",
       "2999  0.0  0.0  0.0  \n",
       "\n",
       "[3000 rows x 599 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2aeb5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(encoded_train+'/df_fe_train.csv.out')\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0724770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8743c78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://sagemaker-us-east-1-930992672261/sagemake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  s3://sagemaker-us-east-1-930992672261/sagemake..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(StringIO('s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out'), header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0de6b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e141ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file = \"xgboost-model\"\n",
    "# booster = pkl.load(open(os.path.join(model_dir, model_file), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fdd757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scrip_transformer = xgb_script_mode_estimator.transformer(\n",
    "                          instance_count=1,\n",
    "                          instance_type='ml.c4.xlarge', accept=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf280d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34m[2022-12-30:18:24:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:49:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:49:INFO] Module humana_model_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:49:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:49:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:49:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=7588 sha256=f37177aaf765ba1bf03c20cf50801debbf5de5898f16d94bcb407e872c1f1049\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-40r63whs/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-model-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [34] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [34] [INFO] Listening at: unix:/tmp/gunicorn.sock (34)\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [34] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2022-12-30 18:24:51 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:52:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:52:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:53:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:53:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:56:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:56:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=11625 sha256=dab9fc9690898e6293ecd43eae2ec1f5c78c9fb60de17507e4845f83743e8788\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-7xjctu5y/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-model-train\n",
      "  Attempting uninstall: humana-model-train\n",
      "    Found existing installation: humana-model-train 1.0.0\n",
      "    Can't uninstall 'humana-model-train'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[35m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=11625 sha256=dab9fc9690898e6293ecd43eae2ec1f5c78c9fb60de17507e4845f83743e8788\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-7xjctu5y/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humana-model-train\n",
      "  Attempting uninstall: humana-model-train\n",
      "    Found existing installation: humana-model-train 1.0.0\n",
      "    Can't uninstall 'humana-model-train'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:18:24:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:18:24:58 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:18:24:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:18:24:58 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:58:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:58:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:58:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:58:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=15835 sha256=f9fb24aee8e2752c6a4def28a5664981d70869394f5b22611d2b7824d817a946\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-wha0zf3v/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-model-train\n",
      "  Attempting uninstall: humana-model-train\n",
      "    Found existing installation: humana-model-train 1.0.0\n",
      "    Can't uninstall 'humana-model-train'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:59:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35m  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=15835 sha256=f9fb24aee8e2752c6a4def28a5664981d70869394f5b22611d2b7824d817a946\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-wha0zf3v/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humana-model-train\n",
      "  Attempting uninstall: humana-model-train\n",
      "    Found existing installation: humana-model-train 1.0.0\n",
      "    Can't uninstall 'humana-model-train'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:59:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:18:24:59 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:59:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:18:24:59 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:59:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:18:24:59 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:59:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:24:59:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:18:24:59 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:59:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:24:59:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=20224 sha256=b763cb49345ae8dcb5f96b059550a1ae274b728cb4e19bc43bc1099324bd5c5d\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-fjppkj9p/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-model-train\n",
      "  Attempting uninstall: humana-model-train\n",
      "    Found existing installation: humana-model-train 1.0.0\n",
      "    Can't uninstall 'humana-model-train'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=20224 sha256=b763cb49345ae8dcb5f96b059550a1ae274b728cb4e19bc43bc1099324bd5c5d\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-fjppkj9p/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humana-model-train\n",
      "  Attempting uninstall: humana-model-train\n",
      "    Found existing installation: humana-model-train 1.0.0\n",
      "    Can't uninstall 'humana-model-train'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:25:01:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:25:01:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:18:25:01 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:18:25:01:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:18:25:01 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:18:25:01 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-12-30:18:25:01:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35mNameError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 227, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/humana_model_train.py\", line 131, in input_fn\n",
      "    df = pd.read_csv(StringIO(input_data),\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: name 'StringIO' is not defined\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:18:25:01 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-12-30T18:24:58.094:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: \u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: Message:\u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: <title>500 Internal Server Error</title>\u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: <h1>Internal Server Error</h1>\u001b[0m\n",
      "\u001b[32m2022-12-30T18:25:01.360:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-30-03-50-32-041/df_fe_test.csv.out: <p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job sagemaker-xgboost-2022-12-30-18-19-56-914: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8691/1288789504.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_scrip_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text/csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     def transform_with_monitoring(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3601\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3602\u001b[0m                 )\n\u001b[0;32m-> 3603\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3604\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3605\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job sagemaker-xgboost-2022-12-30-18-19-56-914: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "xgb_scrip_transformer.transform(data=encoded_test, content_type='text/csv', split_type='Line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f6de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c6a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bf67998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.model import Model\n",
    "# from sagemaker.predictor import RealTimePredictor, csv_serializer, csv_deserializer\n",
    "\n",
    "# trainedmodel = Model('s3://humana-data/xgboost_v2/abalone-dist-xgb/output/sagemaker-xgboost-2022-12-29-23-13-40-880/output/model.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8033c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-xgboost-2022-12-29-23-13-40-880-something\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # import saved sklearn encoder\n",
    "\n",
    "# from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "# xgboost_saved = sess.create_model_from_job(\n",
    "#     training_job_name = \"sagemaker-xgboost-2022-12-29-23-13-40-880\", \n",
    "#     name=\"{}-something\".format(\"sagemaker-xgboost-2022-12-29-23-13-40-880\"),\n",
    "#     role=role,\n",
    "#     env={\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\", \n",
    "#      \"SAGEMAKER_USE_NGINX\": \"True\", \n",
    "#      \"SAGEMAKER_WORKER_CLASS_TYPE\": \"gevent\", \n",
    "#      \"SAGEMAKER_KEEP_ALIVE_SEC\": \"60\", \n",
    "#      \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "#      \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": \"false\",\n",
    "#      \"SAGEMAKER_PROGRAM\": \"humana_model_train.py\", #the entry point present in training-src-files.tar.gz\n",
    "#      \"SAGEMAKER_REGION\": \"us-east-1\",\n",
    "#      \"SAGEMAKER_SUBMIT_DIRECTORY\": \"s3://humana-data/xgboost_v2/abalone-dist-xgb/output/sagemaker-xgboost-2022-12-29-23-13-40-880/output/model.tar.gz\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# xgb_transformer_saved = Transformer(\n",
    "#     xgboost_saved,\n",
    "#     instance_count = 1,\n",
    "#     instance_type = \"ml.c4.xlarge\",\n",
    "#     assemble_with=\"Line\",\n",
    "#     accept=\"text/csv\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74a26d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_transformer_saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fd37ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m[2022-12-29:23:27:57:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-29:23:27:57:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-29:23:27:57:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2022-12-29:23:27:57:INFO] Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-12-29:23:27:57:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-12-29:23:27:57:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-12-29:23:27:57:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=41886 sha256=51bf2dcd78b26eafbb5488d61fa8e9dfe12d0fee6bacf1613cc4d0742d11e6bf\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-mp3pgq2v/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_modules.py\", line 258, in import_module\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/miniconda3/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\u001b[0m\n",
      "\u001b[34mModuleNotFoundError: No module named 'humana_encoder'\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/bin/serve\", line 8, in <module>\n",
      "    sys.exit(serving_entrypoint())\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_xgboost_container/serving.py\", line 169, in serving_entrypoint\n",
      "    server.start(env.ServingEnv().framework_module)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_server.py\", line 86, in start\n",
      "    _modules.import_module(env.module_dir, env.module_name)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_modules.py\", line 263, in import_module\n",
      "    six.reraise(_errors.ImportModuleError, _errors.ImportModuleError(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_modules.py\", line 258, in import_module\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/miniconda3/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ImportModuleError: No module named 'humana_encoder'\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16912/3324043852.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Preprocess training input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_transformer_saved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text/csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for transform job: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mxgb_transformer_saved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransformer_saved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     def transform_with_monitoring(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4225\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Preprocess training input\n",
    "# xgb_transformer_saved.transform(encoded_valid, content_type=\"text/csv\")\n",
    "\n",
    "# print(\"Waiting for transform job: \" + xgb_transformer_saved.latest_transform_job.job_name)\n",
    "# transformer_saved.wait()\n",
    "# # encoded_train_data = xgb_transformer_saved.output_path\n",
    "# # encoded_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdae666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fObj = open(\"model.tar.gz\", 'rb')\n",
    "# key= os.path.join(prefix, model_file_name, 'model.tar.gz')\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4370106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fb026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c242760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3310d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "807abc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import xgboost as xgb\n",
    "\n",
    "# # Download the model artifacts from S3\n",
    "# s3 = boto3.client('s3')\n",
    "# s3.download_file(bucket, 's3://humana-data/xgboost_v2/abalone-dist-xgb/output/sagemaker-xgboost-2022-12-29-23-13-40-880/output/', 'model.tar.gz')\n",
    "\n",
    "# # Load the model from the tar.gz file\n",
    "# model = xgb.Booster()\n",
    "# model.load_model('model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf78eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a216d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainedmodel = sagemaker.model.Model(    \n",
    "#     model_data='s3://humana-data/xgboost_model/output/sagemaker-xgboost-2022-12-29-20-38-26-669/output/model.tar.gz',\n",
    "#     image=container,  \n",
    "#     role=role)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e1756ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.model import Model\n",
    "# from sagemaker.predictor import RealTimePredictor, csv_serializer, csv_deserializer\n",
    "\n",
    "# trainedmodel = Model('s3://humana-data/xgboost_model/output/sagemaker-xgboost-2022-12-29-20-38-26-669/output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21be172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creates a transformer object from the trained model\n",
    "\n",
    "# xgb_transformer = trainedmodel.transformer(\n",
    "#                           instance_count=1,\n",
    "#                           instance_type='ml.m4.xlarge')\n",
    "\n",
    "\n",
    "\n",
    "# # calls that object's transform method to create a transform job\n",
    "# xgb_transformer.transform(data=encoded_valid, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "\n",
    "# xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1cb17",
   "metadata": {},
   "source": [
    "### Another Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27c4f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f5947d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "content_type = 'csv'\n",
    "train_input = TrainingInput(\n",
    "    encoded_train, content_type=content_type\n",
    ")\n",
    "validation_input = TrainingInput(\n",
    "    encoded_valid, content_type=content_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a432b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DEMO-xgboost-churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4610b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'humana-data'\n",
    "prefix = 'xgboost_v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4f23b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-30 01:24:23 Starting - Starting the training job...ProfilerReport-1672363463: InProgress\n",
      "...\n",
      "2022-12-30 01:25:07 Starting - Preparing the instances for training.........\n",
      "2022-12-30 01:26:53 Downloading - Downloading input data...\n",
      "2022-12-30 01:27:19 Training - Downloading the training image...\n",
      "2022-12-30 01:27:47 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-12-30:01:27:46:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-12-30:01:27:46:INFO] File size need to be processed in the node: 32.37mb. Available memory size in the node: 8646.16mb\u001b[0m\n",
      "\u001b[34m[2022-12-30:01:27:46:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[01:27:46] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[01:27:46] 3000x599 matrix with 1797000 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-12-30:01:27:46:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[01:27:46] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[01:27:46] 3000x599 matrix with 1797000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.157667#011validation-error:0.156\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.159333#011validation-error:0.147667\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.159#011validation-error:0.147667\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.159#011validation-error:0.147333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.159#011validation-error:0.147333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.159#011validation-error:0.147333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.159#011validation-error:0.147667\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.158333#011validation-error:0.149\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.158#011validation-error:0.148333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.158667#011validation-error:0.148333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.158333#011validation-error:0.148\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.158333#011validation-error:0.148\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.158333#011validation-error:0.148\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.158#011validation-error:0.148\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.157#011validation-error:0.147667\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.156333#011validation-error:0.148\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.156#011validation-error:0.148667\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.153667#011validation-error:0.148333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.154333#011validation-error:0.148667\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.153333#011validation-error:0.148333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.153333#011validation-error:0.148333\u001b[0m\n",
      "\u001b[34m[01:27:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.154#011validation-error:0.149\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.152667#011validation-error:0.149\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.152#011validation-error:0.148667\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.151667#011validation-error:0.148667\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.150333#011validation-error:0.148333\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.15#011validation-error:0.148667\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.149#011validation-error:0.149\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.149333#011validation-error:0.149333\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.148667#011validation-error:0.149\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.147333#011validation-error:0.149333\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.145333#011validation-error:0.15\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.144667#011validation-error:0.150333\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.143667#011validation-error:0.15\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.143333#011validation-error:0.15\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.143#011validation-error:0.15\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.142#011validation-error:0.150333\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.140667#011validation-error:0.150333\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.140333#011validation-error:0.150667\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.136333#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.137#011validation-error:0.150667\u001b[0m\n",
      "\u001b[34m[01:27:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.135#011validation-error:0.151333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.133667#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.131333#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.131#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.129#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.128#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.127#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.126#011validation-error:0.151\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.126#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.125333#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.123667#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.124#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.123333#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.122667#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.120667#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.12#011validation-error:0.153\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.12#011validation-error:0.153\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.119#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.119#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.119333#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.117#011validation-error:0.151333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.116667#011validation-error:0.151333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.114667#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.113#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.108#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.108333#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.106333#011validation-error:0.151333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.106333#011validation-error:0.151333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.106667#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.106333#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.106333#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.106333#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.105#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.105#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.105667#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.102667#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.102#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.100333#011validation-error:0.153333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.100667#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.099333#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.098667#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.098667#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.098667#011validation-error:0.152333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.096667#011validation-error:0.153\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.096333#011validation-error:0.153333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.096667#011validation-error:0.153667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.091333#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.089333#011validation-error:0.152\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.089#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.088667#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.089333#011validation-error:0.153\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.089333#011validation-error:0.153\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.090333#011validation-error:0.154333\u001b[0m\n",
      "\u001b[34m[01:27:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.088667#011validation-error:0.153\u001b[0m\n",
      "\u001b[34m[01:27:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.088#011validation-error:0.151667\u001b[0m\n",
      "\u001b[34m[01:27:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.086333#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.086333#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.086667#011validation-error:0.152667\u001b[0m\n",
      "\u001b[34m[01:27:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.087#011validation-error:0.153333\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-12-30 01:28:11 Uploading - Uploading generated training model\n",
      "2022-12-30 01:28:11 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 77\n"
     ]
    }
   ],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    base_job_name = model_name,\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "# xgb.fit({'train': train_input, 'validation': validation_input}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d178697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEMO-xgboost-churn'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "457aa744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/xgboost_v4/output/DEMO-xgboost-churn-2022-12-30-01-24-23-627/output/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URI where a pre-trained model is stored\n",
    "model_url = 's3://humana-data/xgboost_v4/output/DEMO-xgboost-churn-2022-12-30-01-24-23-627/output/'\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4c8fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "## Train customised model\n",
    "# sess = sagemaker.Session()\n",
    "\n",
    "# model_uri: URI of our pre-trained model \n",
    "xgb_saved = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    model_uri = model_url, ## load our customised model\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    base_job_name = model_name,\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix))\n",
    "\n",
    "# Most hyper-parameters we have done in the pre-trained model\n",
    "# customised_xgb.set_hyperparameters(num_round=50 #The number of rounds for boosting (only used in the console version of XGBoost)\n",
    "#                         )\n",
    "\n",
    "# start model training\n",
    "# customised_xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b99f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    }
   ],
   "source": [
    "abg_transformer  = xgb_saved.transformer(instance_count = 1,\n",
    "                     instance_type = 'ml.m4.xlarge',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a76d4e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateTransformJob operation: Could not find model \"arn:aws:sagemaker:us-east-1:930992672261:model/demo-xgboost-churn-2022-12-30-01-30-27-323\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3262/2493931966.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calls that object's transform method to create a transform job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mabg_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'S3Prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text/csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_output_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         self.latest_transform_job = _TransformJob.start_new(\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, transformer, data, data_type, content_type, compression_type, split_type, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config)\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtransform_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, job_name, model_name, strategy, max_concurrent_transforms, max_payload, env, input_config, output_config, resource_config, experiment_config, tags, data_processing, model_client_config, batch_data_capture_config)\u001b[0m\n\u001b[1;32m   2784\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m     def _create_model_request(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   4521\u001b[0m             \u001b[0mfunc_name\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mneeded\u001b[0m \u001b[0mintercepting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \"\"\"\n\u001b[0;32m-> 4523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   2782\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating transform job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transform request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateTransformJob operation: Could not find model \"arn:aws:sagemaker:us-east-1:930992672261:model/demo-xgboost-churn-2022-12-30-01-30-27-323\"."
     ]
    }
   ],
   "source": [
    "# calls that object's transform method to create a transform job\n",
    "abg_transformer.transform(data=encoded_valid, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e5383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c687f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2f66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0541675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef23c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9e7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fb639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30003039",
   "metadata": {},
   "source": [
    "## Another Try as framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba5ed56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/xgboost_v5/abalone-dist-xgb/output'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92b6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d614580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c181e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5af78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930fc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7fdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b85d6012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-30 02:48:52 Starting - Starting the training job...\n",
      "2022-12-30 02:49:14 Starting - Preparing the instances for trainingProfilerReport-1672368531: InProgress\n",
      ".........\n",
      "2022-12-30 02:50:46 Downloading - Downloading input data..\u001b[34m[2022-12-30 02:51:03.658 ip-10-0-143-9.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] Module humana_model_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:03:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-model-train\n",
      "  Building wheel for humana-model-train (setup.py): started\n",
      "  Building wheel for humana-model-train (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-model-train: filename=humana_model_train-1.0.0-py2.py3-none-any.whl size=5940 sha256=17fd9e1d925d468e5c66978049b3e750fd0ffd5e54fdbb4588a2fe09155f5614\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-8h__end0/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-model-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-model-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-model-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:05:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:02:51:05:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"gamma\": \"4\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"num_round\": \"50\",\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"subsample\": \"0.7\",\n",
      "        \"verbosity\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2022-12-30-02-48-51-739\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-930992672261/sagemaker-xgboost-2022-12-30-02-48-51-739/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"humana_model_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"humana_model_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"binary:logistic\",\"subsample\":\"0.7\",\"verbosity\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=humana_model_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=humana_model_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-930992672261/sagemaker-xgboost-2022-12-30-02-48-51-739/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"binary:logistic\",\"subsample\":\"0.7\",\"verbosity\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-12-30-02-48-51-739\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-930992672261/sagemaker-xgboost-2022-12-30-02-48-51-739/source/sourcedir.tar.gz\",\"module_name\":\"humana_model_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"humana_model_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"binary:logistic\",\"--subsample\",\"0.7\",\"--verbosity\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=50\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSITY=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m humana_model_train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective binary:logistic --subsample 0.7 --verbosity 1\u001b[0m\n",
      "\u001b[34m[02:51:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.60670#011validation-logloss:0.60694\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.54794#011validation-logloss:0.54866\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.50784#011validation-logloss:0.50905\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.47794#011validation-logloss:0.48365\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.45640#011validation-logloss:0.46406\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.44187#011validation-logloss:0.45185\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.43060#011validation-logloss:0.44300\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.42311#011validation-logloss:0.43702\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.41426#011validation-logloss:0.43227\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.40785#011validation-logloss:0.42860\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.39968#011validation-logloss:0.42626\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.39454#011validation-logloss:0.42568\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.38816#011validation-logloss:0.42553\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.38341#011validation-logloss:0.42430\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.37877#011validation-logloss:0.42525\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.37458#011validation-logloss:0.42489\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.37137#011validation-logloss:0.42614\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.36803#011validation-logloss:0.42658\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.36186#011validation-logloss:0.42789\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.35958#011validation-logloss:0.42859\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.35523#011validation-logloss:0.42876\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.35133#011validation-logloss:0.42781\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.34667#011validation-logloss:0.42914\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.34301#011validation-logloss:0.42969\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.34157#011validation-logloss:0.42967\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.33639#011validation-logloss:0.43038\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.33209#011validation-logloss:0.43267\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.32884#011validation-logloss:0.43379\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.32614#011validation-logloss:0.43408\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.32350#011validation-logloss:0.43494\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.32177#011validation-logloss:0.43568\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.31877#011validation-logloss:0.43502\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.31605#011validation-logloss:0.43699\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.31233#011validation-logloss:0.43832\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.30808#011validation-logloss:0.44004\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.30418#011validation-logloss:0.44172\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.30145#011validation-logloss:0.44248\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.29847#011validation-logloss:0.44317\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.29547#011validation-logloss:0.44411\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.29191#011validation-logloss:0.44521\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.29094#011validation-logloss:0.44600\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.28865#011validation-logloss:0.44746\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.28632#011validation-logloss:0.44859\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.28483#011validation-logloss:0.44859\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.28161#011validation-logloss:0.44986\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.27804#011validation-logloss:0.45004\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.27640#011validation-logloss:0.45099\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.27554#011validation-logloss:0.45158\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.27351#011validation-logloss:0.45117\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.27110#011validation-logloss:0.45184\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-12-30 02:51:17 Training - Training image download completed. Training in progress.\n",
      "2022-12-30 02:51:17 Uploading - Uploading generated training model\n",
      "2022-12-30 02:51:55 Completed - Training job completed\n",
      "Training seconds: 42\n",
      "Billable seconds: 42\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"verbosity\":\"1\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'DEMO-xgboost-as-a-framework'\n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'abalone-xgb-framework')\n",
    "\n",
    "# construct a SageMaker XGBoost estimator\n",
    "# specify the entry_point to your xgboost training script\n",
    "estimator = XGBoost(entry_point = \"humana_script/humana_model_train.py\", \n",
    "                    framework_version='1.5-1',\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    output_path=output_path)\n",
    "\n",
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(encoded_train, content_type=content_type)\n",
    "validation_input = TrainingInput(encoded_valid, content_type=content_type)\n",
    "\n",
    "# execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "251cbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file_path = 's3://sagemaker-us-east-1-930992672261/DEMO-xgboost-as-a-framework/abalone-xgb-framework/output/sagemaker-xgboost-2022-12-30-02-27-05-158/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "390b8b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.2'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_xgb = estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge')\n",
    "\n",
    "valid_test_df = pd.read_csv(encoded_valid+'/df_fe_valid.csv.out', header=None)\n",
    "valid_test_df = valid_test_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b702e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84e35a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3262/161759224.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  calls that object's transform method to create a transform job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrained_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text/csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mlocal_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_mode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_pipeline_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid S3 URI: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "#  calls that object's transform method to create a transform job\n",
    "# trained_xgb.transform(data=valid_test_df, data_type='csv', content_type='text/csv', split_type='Line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3004c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "\n",
    "# xgb_model = xgb.Booster()\n",
    "# xgb_model.load_model(model_file_path)\n",
    "# # xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c4d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ea017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01945c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7271e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
