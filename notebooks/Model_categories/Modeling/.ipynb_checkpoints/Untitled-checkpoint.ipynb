{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31ce156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 799 ms, sys: 136 ms, total: 934 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-xgboost-inference-script-mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d5c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 193 ms, sys: 21.9 ms, total: 215 ms\n",
      "Wall time: 665 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/abalone'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s3 = boto3.client(\"s3\")\n",
    "# Load the dataset\n",
    "FILE_DATA = \"abalone\"\n",
    "s3.download_file(\n",
    "    \"sagemaker-sample-files\", f\"datasets/tabular/uci_abalone/abalone.libsvm\", FILE_DATA\n",
    ")\n",
    "sagemaker.Session().upload_data(FILE_DATA, bucket=bucket, key_prefix=prefix + \"/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9a5386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "\n",
    "job_name = \"DEMO-xgboost-inference-script-mode-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "}\n",
    "\n",
    "instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "xgb_script_mode_estimator = XGBoost(\n",
    "    entry_point=\"abalone.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=\"1.5-1\",\n",
    "    output_path=\"s3://{}/{}/{}/output\".format(bucket, prefix, job_name),\n",
    ")\n",
    "\n",
    "content_type = \"text/csv\"\n",
    "train_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}/\".format(bucket, prefix, \"train\"), content_type=content_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60a6a070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"s3://{}/{}/{}/\".format(bucket, prefix, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa25da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-30 21:15:23 Starting - Starting the training job...\n",
      "2022-12-30 21:15:48 Starting - Preparing the instances for trainingProfilerReport-1672434923: InProgress\n",
      ".........\n",
      "2022-12-30 21:17:08 Downloading - Downloading input data..\u001b[34m[2022-12-30 21:17:30.687 ip-10-2-124-236.ec2.internal:8 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] Module abalone does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:30:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: abalone\n",
      "  Building wheel for abalone (setup.py): started\n",
      "  Building wheel for abalone (setup.py): finished with status 'done'\n",
      "  Created wheel for abalone: filename=abalone-1.0.0-py2.py3-none-any.whl size=6396 sha256=e72c477756115b109c35aca872e4e6a1ab50c415fab3bb17798e40048d095e59\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-d59ggdul/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built abalone\u001b[0m\n",
      "\u001b[34mInstalling collected packages: abalone\u001b[0m\n",
      "\u001b[34mSuccessfully installed abalone-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:32:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:17:32:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"gamma\": \"4\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"num_round\": \"50\",\n",
      "        \"objective\": \"reg:squarederror\",\n",
      "        \"subsample\": \"0.7\",\n",
      "        \"verbosity\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-930992672261/DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"abalone\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"abalone.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=abalone.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=abalone\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-930992672261/DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-930992672261/DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22/source/sourcedir.tar.gz\",\"module_name\":\"abalone\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"abalone.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\",\"--verbosity\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=50\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=reg:squarederror\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSITY=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m abalone --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:squarederror --subsample 0.7 --verbosity 2\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.40004#011validation-rmse:0.40004\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.32005#011validation-rmse:0.32005\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.25607#011validation-rmse:0.25607\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.20487#011validation-rmse:0.20487\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.16391#011validation-rmse:0.16391\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.13114#011validation-rmse:0.13114\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.10492#011validation-rmse:0.10492\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.08394#011validation-rmse:0.08394\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.06716#011validation-rmse:0.06716\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.05373#011validation-rmse:0.05373\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.04299#011validation-rmse:0.04299\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.03440#011validation-rmse:0.03440\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.02752#011validation-rmse:0.02752\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.02202#011validation-rmse:0.02202\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.01761#011validation-rmse:0.01761\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.01409#011validation-rmse:0.01409\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.01128#011validation-rmse:0.01128\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.00902#011validation-rmse:0.00902\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.00722#011validation-rmse:0.00722\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.00577#011validation-rmse:0.00577\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.00462#011validation-rmse:0.00462\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.00370#011validation-rmse:0.00370\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.00296#011validation-rmse:0.00296\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.00237#011validation-rmse:0.00237\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.00189#011validation-rmse:0.00189\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.00152#011validation-rmse:0.00152\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.00121#011validation-rmse:0.00121\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.00097#011validation-rmse:0.00097\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.00078#011validation-rmse:0.00078\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.00062#011validation-rmse:0.00062\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.00050#011validation-rmse:0.00050\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.00040#011validation-rmse:0.00040\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.00032#011validation-rmse:0.00032\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.00025#011validation-rmse:0.00025\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.00020#011validation-rmse:0.00020\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.00016#011validation-rmse:0.00016\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.00013#011validation-rmse:0.00013\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.00010#011validation-rmse:0.00010\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.00008#011validation-rmse:0.00008\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.00007#011validation-rmse:0.00007\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.00005#011validation-rmse:0.00005\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.00004#011validation-rmse:0.00004\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.00003#011validation-rmse:0.00003\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.00003#011validation-rmse:0.00003\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.00002#011validation-rmse:0.00002\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.00002#011validation-rmse:0.00002\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.00001#011validation-rmse:0.00001\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.00001#011validation-rmse:0.00001\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.00001#011validation-rmse:0.00001\u001b[0m\n",
      "\u001b[34m[21:17:33] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.00001#011validation-rmse:0.00001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-12-30 21:17:51 Training - Training image download completed. Training in progress.\n",
      "2022-12-30 21:17:51 Uploading - Uploading generated training model\n",
      "2022-12-30 21:17:51 Completed - Training job completed\n",
      "Training seconds: 42\n",
      "Billable seconds: 42\n"
     ]
    }
   ],
   "source": [
    "xgb_script_mode_estimator.fit({\"train\": train_input, \"validation\": train_input}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7971f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e641ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22/output/DEMO-xgboost-inference-script-mode-2022-12-30-21-15-22/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "model_data = xgb_script_mode_estimator.model_data\n",
    "print(model_data)\n",
    "\n",
    "xgb_inference_model = XGBoostModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    framework_version=\"1.5-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7342bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ecabed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scrip_transformer = xgb_inference_model.transformer(instance_count=1,\n",
    "                          instance_type='ml.c4.xlarge', accept=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e6ffe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34m[2022-12-30:21:27:03:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:03:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:03:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:03:INFO] Module inference does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:03:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:03:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:03:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: inference\n",
      "  Building wheel for inference (setup.py): started\n",
      "  Building wheel for inference (setup.py): finished with status 'done'\n",
      "  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=4054 sha256=0344883ba5975406f07c7fceaad5f9d4a3485e974db45940dd3f42a2c39cbcf2\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-tghc8qrs/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built inference\u001b[0m\n",
      "\u001b[34mInstalling collected packages: inference\u001b[0m\n",
      "\u001b[34mSuccessfully installed inference-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [34] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [34] [INFO] Listening at: unix:/tmp/gunicorn.sock (34)\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [34] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2022-12-30 21:27:05 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:11:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:11:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: inference\n",
      "  Building wheel for inference (setup.py): started\n",
      "  Building wheel for inference (setup.py): finished with status 'done'\n",
      "  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=6316 sha256=93217fa8968a88da0825223da845c256c60c4384ace9a59a156ab2ef86a68270\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-da3gl3gm/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built inference\u001b[0m\n",
      "\u001b[34mInstalling collected packages: inference\n",
      "  Attempting uninstall: inference\n",
      "    Found existing installation: inference 1.0.0\n",
      "    Can't uninstall 'inference'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34mSuccessfully installed inference-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:21:27:13 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:13:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:13:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: inference\n",
      "  Building wheel for inference (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for inference (setup.py): finished with status 'done'\n",
      "  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=8761 sha256=9935a522d9fe225b507c63aed1d5b581275dbae0b101270fe00a5a52d4edf581\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-tk95m8wp/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built inference\u001b[0m\n",
      "\u001b[34mInstalling collected packages: inference\n",
      "  Attempting uninstall: inference\n",
      "    Found existing installation: inference 1.0.0\n",
      "    Can't uninstall 'inference'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34mSuccessfully installed inference-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:21:27:14 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:15:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:15:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: inference\n",
      "  Building wheel for inference (setup.py): started\n",
      "  Building wheel for inference (setup.py): finished with status 'done'\n",
      "  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=11378 sha256=0af19984bf4f7c438dc0d29fad6f72780ff5fa8aa02bf551e405fb26792e32b6\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-rydrv4r7/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built inference\u001b[0m\n",
      "\u001b[34mInstalling collected packages: inference\n",
      "  Attempting uninstall: inference\n",
      "    Found existing installation: inference 1.0.0\n",
      "    Can't uninstall 'inference'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34mSuccessfully installed inference-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-12-30T21:27:14.998:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.680:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.680:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: \u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.680:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: Message:\u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.680:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.681:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: <title>500 Internal Server Error</title>\u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.681:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: <h1>Internal Server Error</h1>\u001b[0m\n",
      "\u001b[32m2022-12-30T21:27:16.681:[sagemaker logs]: sagemaker-us-east-1-930992672261/sagemaker/DEMO-xgboost-inference-script-mode/train/lib_abalone/abalone: <p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35m[2022-12-30:21:27:16:ERROR] Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mxgboost.core.XGBoostError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 199, in transform\n",
      "    result = self._transform_fn(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 231, in _default_transform_fn\n",
      "    prediction = self._predict_fn(data, model)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 95, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/ml/code/inference.py\", line 43, in predict_fn\n",
      "    prediction = model.predict(input_data)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 1913, in predict\n",
      "    _check_call(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[35msagemaker_containers._errors.ClientError: [21:27:16] ../src/learner.cc:1257: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (8 vs. 9) : Number of columns does not match number of features in booster.\u001b[0m\n",
      "\u001b[35mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x19cab9) [0x7fee2ead3ab9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa8ad) [0x7fee2eae18ad]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aa93d) [0x7fee2eae193d]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1aac2d) [0x7fee2eae1c2d]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDMatrix+0x346) [0x7fee2e9d1d46]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fee693369dd]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7fee69336067]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7fee6934f1e9]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7fee6934fc95]\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Dec/2022:21:27:16 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job sagemaker-xgboost-2022-12-30-21-22-14-717: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11266/1291623149.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text/libsvm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_scrip_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"s3://{}/{}/{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lib_abalone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     def transform_with_monitoring(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3601\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3602\u001b[0m                 )\n\u001b[0;32m-> 3603\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3604\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3605\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job sagemaker-xgboost-2022-12-30-21-22-14-717: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "content_type = \"text/libsvm\"\n",
    "xgb_scrip_transformer.transform(data=\"s3://{}/{}/{}/{}\".format(bucket, prefix, \"train\", \"lib_abalone\"), content_type=content_type, split_type='Line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6953a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.inputs.TrainingInput at 0x7fe0946dc0d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647817f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
