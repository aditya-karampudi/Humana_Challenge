{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395e0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "\n",
    "# S3 prefix\n",
    "bucket = \"humana-data\"\n",
    "prefix = \"humana-Linearclass-pipeline-condition-credit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8b4a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/rawdata/original_raw_files/train'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_input = 's3://{}/rawdata/original_raw_files/train'.format(bucket)\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcb7a8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/rawdata/original_raw_files/valid'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input = 's3://{}/rawdata/original_raw_files/valid'.format(bucket)\n",
    "valid_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe1fd88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://humana-data/intermediate/data/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fe_input = 's3://{}/intermediate/data/'.format(bucket)\n",
    "train_fe_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8170c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK_VERSION = \"1.0-1\"\n",
    "script_dir = \"humana_script\"\n",
    "script_path = \"humana_preprocessing.py\"\n",
    "\n",
    "script_dependent_dir = script_dir + '/' + 'humana_package/'\n",
    "script_dependent_dir\n",
    "\n",
    "sklearn_train_processor = SKLearnProcessor(\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    role=role, instance_type=\"ml.c4.xlarge\", instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8a47d",
   "metadata": {},
   "source": [
    "#### Train Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad1fbacc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2022-12-18-01-22-47-439\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://humana-data/rawdata/original_raw_files/train', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-22-47-439/input/input-2', 'LocalPath': '/opt/ml/processing/input/code/humana_package/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-22-47-439/input/code/humana_preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'df_fe', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-22-47-439/output/df_fe', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}]\n",
      "................................\u001b[34mThe files used for processing the train data ['/opt/ml/processing/input/dependent.csv', '/opt/ml/processing/input/credit.csv', '/opt/ml/processing/input/condition.csv']\u001b[0m\n",
      "\u001b[34mSuccessfully imported data from S3. Shape of the train data (10000, 438)\u001b[0m\n",
      "\u001b[34m0    0\u001b[0m\n",
      "\u001b[34m1    0\u001b[0m\n",
      "\u001b[34m2    0\u001b[0m\n",
      "\u001b[34m3    0\u001b[0m\n",
      "\u001b[34m4    0\u001b[0m\n",
      "\u001b[34mName: transportation_issues, dtype: int64\u001b[0m\n",
      "\u001b[34mSuccessfully imported data from S3. Shape of the train data (10000, 438)\u001b[0m\n",
      "\u001b[34mPreprocessed train data\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_train_processor.run(code = script_dir + '/' + script_path,\n",
    "                     inputs = [ProcessingInput(source = train_input, destination = \"/opt/ml/processing/input\"),\n",
    "                              ProcessingInput(source = script_dependent_dir, \n",
    "                                              destination = \"/opt/ml/processing/input/code/humana_package/\")\n",
    "                              ],\n",
    "                     outputs = [ProcessingOutput(output_name = \"df_fe\", source = \"/opt/ml/processing/train\"),\n",
    "                               ],\n",
    "                      arguments = ['--train_or_test', \"train\"],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8436e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6844143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-22-47-439/output/df_fe'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_job_description = sklearn_train_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"df_fe\":\n",
    "        preprocessed_train_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "preprocessed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b9f26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(preprocessed_data + \"/df_fe_train.csv\", header=None,skiprows=1)\n",
    "# df.isna().sum().sum()\n",
    "# df.head()\n",
    "\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "febd3dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humana_script/humana_package/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dependent_dir = script_dir + '/' + 'humana_package/'\n",
    "script_dependent_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7a66c",
   "metadata": {},
   "source": [
    "#### Train data fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd6985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_point humana_script/humana_encoder.py\n",
      "humana_script/humana_package/\n",
      "2022-12-18 01:28:35 Starting - Starting the training job...\n",
      "2022-12-18 01:29:01 Starting - Preparing the instances for trainingProfilerReport-1671326915: InProgress\n",
      "............\n",
      "2022-12-18 01:31:00 Downloading - Downloading input data...\n",
      "2022-12-18 01:31:28 Training - Training image download completed. Training in progress..\u001b[34m2022-12-18 01:31:29,724 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:29,727 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:29,735 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:29,936 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:29,946 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:29,957 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:29,965 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2022-12-18-01-28-35-278\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-28-35-278/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"humana_encoder\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"humana_encoder.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=humana_encoder.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=humana_encoder\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-28-35-278/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-12-18-01-28-35-278\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-18-01-28-35-278/source/sourcedir.tar.gz\",\"module_name\":\"humana_encoder\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"humana_encoder.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python humana_encoder.py\u001b[0m\n",
      "\u001b[34m/opt/ml/output/data model /opt/ml/model train /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/train/df_fe_train.csv']\u001b[0m\n",
      "\u001b[34m(3000, 411)\u001b[0m\n",
      "\u001b[34mIndex(['credit_bal_1stmtgcredit_60dpd', 'credit_bal_agencyfirstmtg_60dpd',\n",
      "       'credit_bal_heloc_60dpd', 'credit_bal_nonagnfirstmtg_60dpd',\n",
      "       'credit_bal_nonmtgcredit_60dpd', 'credit_bal_studentloan_60dpd',\n",
      "       'credit_bal_totalallcredit_60dpd', 'credit_bal_autobank',\n",
      "       'credit_bal_autofinance', 'credit_bal_consumerfinance',\n",
      "       ...\n",
      "       'sor_ind_sum', 'sor_pmpm_sum', 'trm_ind_sum', 'trm_pmpm_sum',\n",
      "       'vco_ind_sum', 'vco_pmpm_sum', 'total_ind', 'total_pmpm',\n",
      "       'service_bool', 'transportation_issues'],\n",
      "      dtype='object', length=411)\u001b[0m\n",
      "\u001b[34mfloat64     236\u001b[0m\n",
      "\u001b[34mcategory    136\u001b[0m\n",
      "\u001b[34mcategory     36\u001b[0m\n",
      "\u001b[34mcategory      1\u001b[0m\n",
      "\u001b[34mint64         1\u001b[0m\n",
      "\u001b[34mdtype: int64\u001b[0m\n",
      "\u001b[34mTrain data shape after preprocessing: (3000, 410)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:31:31,845 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-12-18 01:32:00 Uploading - Uploading generated training model\n",
      "2022-12-18 01:32:00 Completed - Training job completed\n",
      "Training seconds: 56\n",
      "Billable seconds: 56\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"1.0-1\"\n",
    "script_path = \"humana_encoder.py\"\n",
    "script_dir = \"humana_script\"\n",
    "\n",
    "sklearn_encoder = SKLearn(\n",
    "    entry_point= script_path,\n",
    "    source_dir = script_dependent_dir,\n",
    "    role=role,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "print(\"entry_point\", script_dir +\"/\" + script_path)\n",
    "print(script_dependent_dir)\n",
    "sklearn_encoder.fit({\"train\": preprocessed_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "087ac509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn_encoder.transformer(\n",
    "    instance_count=1, instance_type=\"ml.c4.xlarge\", assemble_with=\"Line\", accept=\"text/csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3e7b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m2022-12-18 01:37:38,096 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,098 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,099 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,261 INFO - sagemaker-containers - Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,261 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,262 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,262 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=29200 sha256=9f6d14902cfc3d6cbb2db4b0ee92c0484b50461e734791ed1a0f9837b59def65\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-u64lc_1j/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:44,416 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Dec/2022:01:37:44 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Dec/2022:01:37:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:45,124 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Dec/2022:01:37:47 +0000] \"POST /invocations HTTP/1.1\" 200 16972015 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Dec/2022:01:37:47 +0000] \"POST /invocations HTTP/1.1\" 200 16972015 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-12-18T01:37:45.005:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "Waiting for transform job: sagemaker-scikit-learn-2022-12-18-01-32-39-510\n",
      "\u001b[34m2022-12-18 01:37:38,096 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,098 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,099 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,096 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,098 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,099 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,261 INFO - sagemaker-containers - Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,261 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,262 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:38,262 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,261 INFO - sagemaker-containers - Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,261 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,262 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:38,262 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=29200 sha256=9f6d14902cfc3d6cbb2db4b0ee92c0484b50461e734791ed1a0f9837b59def65\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-u64lc_1j/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2022-12-18 01:37:40 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=29200 sha256=9f6d14902cfc3d6cbb2db4b0ee92c0484b50461e734791ed1a0f9837b59def65\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-u64lc_1j/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[35mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2022-12-18 01:37:40 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:44,416 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Dec/2022:01:37:44 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Dec/2022:01:37:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2022-12-18 01:37:45,124 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:44,416 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Dec/2022:01:37:44 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Dec/2022:01:37:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2022-12-18 01:37:45,124 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Dec/2022:01:37:47 +0000] \"POST /invocations HTTP/1.1\" 200 16972015 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Dec/2022:01:37:47 +0000] \"POST /invocations HTTP/1.1\" 200 16972015 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-12-18T01:37:45.005:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training input\n",
    "transformer.transform(preprocessed_train_data, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "encoded_train = transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09967a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "ll_image = retrieve(\"linear-learner\", boto3.Session().region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-18 02:10:47 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "s3_ll_output_key_prefix = \"ll_training_output\"\n",
    "s3_ll_output_location = \"s3://{}/{}/{}/{}\".format(\n",
    "    bucket, prefix, s3_ll_output_key_prefix, \"ll_model\"\n",
    ")\n",
    "\n",
    "ll_estimator = sagemaker.estimator.Estimator(\n",
    "    ll_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.2xlarge\",\n",
    "    volume_size=20,\n",
    "    max_run=3600,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_ll_output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "ll_estimator.set_hyperparameters(feature_dim=10, predictor_type=\"regressor\", mini_batch_size=32)\n",
    "\n",
    "ll_train_data = sagemaker.inputs.TrainingInput(\n",
    "    encoded_train,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": ll_train_data}\n",
    "ll_estimator.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032b2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7e1fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_path = script_dir + \"/\"+ \"train.py\"\n",
    "# train_model_path\n",
    "\n",
    "# hyperparameters = {\n",
    "#     \"max_depth\":5,\n",
    "#     \"eta\":0.2,\n",
    "#     \"gamma\":4,\n",
    "#     \"min_child_weight\":6,\n",
    "#     \"subsample\":0.8,\n",
    "#     \"verbosity\":0,\n",
    "#     \"objective\":\"binary:logistic\",\n",
    "#     \"num_round\":100,}\n",
    "\n",
    "# # from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# # sklearn = SKLearn(\n",
    "# #     entry_point= train_model_path, framework_version=\"0.20.0\", instance_type=\"ml.m5.xlarge\", role=role\n",
    "# # )\n",
    "\n",
    "# from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# xgb_estimator = XGBoost(\n",
    "#     entry_point=train_model_path,\n",
    "#     hyperparameters=hyperparameters,\n",
    "#     role=role,\n",
    "#     instance_count=1,\n",
    "#     instance_type=\"ml.m5.2xlarge\",\n",
    "#     framework_version=\"1.0-1\",\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xgb_estimator.fit({\"train\": encoded_train+ \"/df_fe_train.csv.out\"})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training_job_description = sklearn.jobs[-1].describe()\n",
    "# model_data_s3_uri = \"{}{}/{}\".format(\n",
    "#     training_job_description[\"OutputDataConfig\"][\"S3OutputPath\"],\n",
    "#     training_job_description[\"TrainingJobName\"],\n",
    "#     \"output/model.tar.gz\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdc9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663827f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb53b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5586d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e36375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa505c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e43603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c557beb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Valid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92991cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK_VERSION = \"1.0-1\"\n",
    "script_dir = \"humana_script\"\n",
    "script_path = \"humana_preprocessing.py\"\n",
    "\n",
    "script_dependent_dir = script_dir + '/' + 'humana_package/'\n",
    "script_dependent_dir\n",
    "\n",
    "sklearn_valid_processor = SKLearnProcessor(\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    role=role, instance_type=\"ml.c4.xlarge\", instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df2c236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2022-12-17-23-01-09-981\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://humana-data/rawdata/original_raw_files/valid', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-17-23-01-09-981/input/input-2', 'LocalPath': '/opt/ml/processing/input/code/humana_package/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-17-23-01-09-981/input/code/humana_preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'df_fe', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-17-23-01-09-981/output/df_fe', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................\u001b[34mThe files used for processing the test data ['/opt/ml/processing/input/dependent.csv', '/opt/ml/processing/input/credit.csv', '/opt/ml/processing/input/condition.csv']\u001b[0m\n",
      "\u001b[34mSuccessfully imported data from S3. Shape of the test data (4000, 438)\u001b[0m\n",
      "\u001b[34m0    0\u001b[0m\n",
      "\u001b[34m1    0\u001b[0m\n",
      "\u001b[34m2    0\u001b[0m\n",
      "\u001b[34m3    1\u001b[0m\n",
      "\u001b[34m4    0\u001b[0m\n",
      "\u001b[34mName: transportation_issues, dtype: int64\u001b[0m\n",
      "\u001b[34mSuccessfully imported data from S3. Shape of the test data (4000, 438)\u001b[0m\n",
      "\u001b[34mPreprocessed test data\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sklearn_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32157/1824415582.py\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                      )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpreprocessing_job_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutput_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_job_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ProcessingOutputConfig\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn_processor' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_valid_processor.run(code = script_dir + '/' + script_path,\n",
    "                     inputs = [ProcessingInput(source = valid_input, destination = \"/opt/ml/processing/input\"),\n",
    "                              ProcessingInput(source = script_dependent_dir, \n",
    "                                              destination = \"/opt/ml/processing/input/code/humana_package/\")\n",
    "                              ],\n",
    "                     outputs = [ProcessingOutput(output_name = \"df_fe\", source = \"/opt/ml/processing/test\"),\n",
    "                               ],\n",
    "                      arguments = ['--train_or_test', \"test\"],\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d202648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-930992672261/sagemaker-scikit-learn-2022-12-17-23-01-09-981/output/df_fe'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preprocessing_job_description = sklearn_valid_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"df_fe\":\n",
    "        preprocessed_valid_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "preprocessed_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9cf374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn_encoder.transformer(\n",
    "    instance_count=1, instance_type=\"ml.c4.xlarge\", assemble_with=\"Line\", accept=\"text/csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ef02835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m2022-12-17 23:14:47,108 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,110 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,111 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,294 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=29200 sha256=6fd6b3b3d5d5724042aeeb67fe4d0309bd745ce4c7b697d84d3cd76b07cf5eb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-4dm85ke0/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:57,746 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:57,746 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:58,335 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:58,897 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:58,335 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:58,897 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Dec/2022:23:15:00 +0000] \"POST /invocations HTTP/1.1\" 200 16962718 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Dec/2022:23:15:00 +0000] \"POST /invocations HTTP/1.1\" 200 16962718 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-12-17T23:14:58.818:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "Waiting for transform job: sagemaker-scikit-learn-2022-12-17-23-09-49-063\n",
      "\u001b[34m2022-12-17 23:14:47,108 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,110 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,111 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,108 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,110 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,111 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:47,294 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=29200 sha256=6fd6b3b3d5d5724042aeeb67fe4d0309bd745ce4c7b697d84d3cd76b07cf5eb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-4dm85ke0/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[34mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Module humana_encoder does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,293 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:47,294 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: humana-encoder\n",
      "  Building wheel for humana-encoder (setup.py): started\n",
      "  Building wheel for humana-encoder (setup.py): finished with status 'done'\n",
      "  Created wheel for humana-encoder: filename=humana_encoder-1.0.0-py2.py3-none-any.whl size=29200 sha256=6fd6b3b3d5d5724042aeeb67fe4d0309bd745ce4c7b697d84d3cd76b07cf5eb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-4dm85ke0/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built humana-encoder\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humana-encoder\u001b[0m\n",
      "\u001b[35mSuccessfully installed humana-encoder-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2022-12-17 23:14:49 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2022-12-17 23:14:49 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:57,746 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:57,746 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:58,335 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2022-12-17 23:14:58,897 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:58,335 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Dec/2022:23:14:58 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2022-12-17 23:14:58,897 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Dec/2022:23:15:00 +0000] \"POST /invocations HTTP/1.1\" 200 16962718 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m169.254.255.130 - - [17/Dec/2022:23:15:00 +0000] \"POST /invocations HTTP/1.1\" 200 16962718 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-12-17T23:14:58.818:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training input\n",
    "transformer.transform(preprocessed_valid_data, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "encoded_valid_data = transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ae007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460dae17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ddca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acec9d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humana_script/train.py'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d90275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71eddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50d15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e60c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf3c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee9852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
