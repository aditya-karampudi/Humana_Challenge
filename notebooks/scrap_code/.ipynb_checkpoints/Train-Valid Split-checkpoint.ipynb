{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d3aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import os\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dba39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8beb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rawdata/original_raw_files/full_data/CMS.csv',\n",
       " 'rawdata/original_raw_files/full_data/Condition.csv',\n",
       " 'rawdata/original_raw_files/full_data/Credit.csv',\n",
       " 'rawdata/original_raw_files/full_data/Demo.csv',\n",
       " 'rawdata/original_raw_files/full_data/Lab.csv',\n",
       " 'rawdata/original_raw_files/full_data/Medical Claims.csv',\n",
       " 'rawdata/original_raw_files/full_data/Not sure.csv',\n",
       " 'rawdata/original_raw_files/full_data/Others.csv',\n",
       " 'rawdata/original_raw_files/full_data/Pharm.csv',\n",
       " 'rawdata/original_raw_files/full_data/dependent.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_full_data = 'rawdata/original_raw_files/full_data'\n",
    "prefix_train = 'rawdata/original_raw_files/train'\n",
    "prefix_valid = 'rawdata/original_raw_files/valid'\n",
    "bucket = \"humana-data\"\n",
    "\n",
    "\n",
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket, Prefix=prefix_full_data)['Contents']\n",
    "\n",
    "rawfile_names = [key['Key'] for key in contents]\n",
    "rawfile_names = [x for x in rawfile_names if x.endswith('.csv')]\n",
    "rawfile_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a4811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3276242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful S3 get_object response. Status - 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'H7K7EY7TYCBE7E4C',\n",
       "  'HostId': '8yLAUapMwH0bW+NZZzV4Ot2jkaDFq/5PyrYPGunnQq6JYgG+vci0/clX7jAqncMvLOAlbNF+vf0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '8yLAUapMwH0bW+NZZzV4Ot2jkaDFq/5PyrYPGunnQq6JYgG+vci0/clX7jAqncMvLOAlbNF+vf0=',\n",
       "   'x-amz-request-id': 'H7K7EY7TYCBE7E4C',\n",
       "   'date': 'Wed, 16 Nov 2022 19:06:29 GMT',\n",
       "   'x-amz-version-id': 'Uyu5wifroddd2lMBaLeF4GEqQ8KRBJVF',\n",
       "   'etag': '\"25ad293d12eed88a5a0885ddfa6abf57\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"25ad293d12eed88a5a0885ddfa6abf57\"',\n",
       " 'VersionId': 'Uyu5wifroddd2lMBaLeF4GEqQ8KRBJVF'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the demo file\n",
    "response = conn.get_object(Bucket=bucket, Key='rawdata/original_raw_files/full_data/Condition.csv')\n",
    "status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "if status == 200:\n",
    "    print(f\"Successful S3 get_object response. Status - {status}\")\n",
    "    condition_df = pd.read_csv(response.get(\"Body\"))\n",
    "else:\n",
    "    print(f\"Unsuccessful S3 get_object response. Status - {status}\")\n",
    "\n",
    "condition_df.columns = condition_df.columns.str.lower()\n",
    "condition_df = condition_df.set_index('person_id_syn')\n",
    "\n",
    "# condition_df = dependent_df.merge(condition_df, left_index=True, right_index=True)\n",
    "\n",
    "condition_train_df = condition_df.sample(frac= 0.7)\n",
    "\n",
    "train_indexes = pd.DataFrame(condition_train_df.reset_index()['person_id_syn'].to_dict().items(),\n",
    "                             columns = ['index_num', 'person_id_syn'])\n",
    "\n",
    "condition_valid_df = condition_df[~(condition_df.index.isin(train_indexes['person_id_syn']))]\n",
    "valid_indexes = pd.DataFrame(condition_valid_df.reset_index()['person_id_syn'].to_dict().items(), columns = ['index_num', 'person_id_syn'])\n",
    "\n",
    "# Saving train\n",
    "# filename = 'condition.parquet.gzip'\n",
    "# s3_train_url = 's3://{}/{}/{}'.format(bucket, prefix_train, filename)\n",
    "# s3_valid_url = 's3://{}/{}/{}'.format(bucket, prefix_valid, filename)\n",
    "# condition_train_df.to_parquet(s3_train_url, compression='gzip')\n",
    "# condition_valid_df.to_parquet(s3_valid_url, compression='gzip')\n",
    "\n",
    "\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "csv_buffer = StringIO()\n",
    "condition_train_df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename_condition = \"condition.csv\"\n",
    "\n",
    "fe_path = prefix_train + '/' + filename_condition\n",
    "s3_resource.Object(bucket, fe_path).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "condition_valid_df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename_condition = \"condition.csv\"\n",
    "\n",
    "fe_path = prefix_valid + '/' + filename_condition\n",
    "s3_resource.Object(bucket, fe_path).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c67a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fcab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful S3 get_object response. Status - 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'KV62H82P6C05D2CY',\n",
       "  'HostId': 'EtEpe0XPLVsp3Yr/Fq5RSfEhm4YzAa5dZGOP1NfvWlMV4yx0umHy2y+dTEAv3KeKWYIN+2tBFnk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'EtEpe0XPLVsp3Yr/Fq5RSfEhm4YzAa5dZGOP1NfvWlMV4yx0umHy2y+dTEAv3KeKWYIN+2tBFnk=',\n",
       "   'x-amz-request-id': 'KV62H82P6C05D2CY',\n",
       "   'date': 'Wed, 16 Nov 2022 19:06:30 GMT',\n",
       "   'x-amz-version-id': 'ZY1_Fi7zTVzNgHENeU7pGpFGBXTSo6FF',\n",
       "   'etag': '\"bd6ae78448a98df27669c7834bfd8d85\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"bd6ae78448a98df27669c7834bfd8d85\"',\n",
       " 'VersionId': 'ZY1_Fi7zTVzNgHENeU7pGpFGBXTSo6FF'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependent\n",
    "# Get the demo file\n",
    "response = conn.get_object(Bucket=bucket, Key='rawdata/original_raw_files/full_data/dependent.csv')\n",
    "status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "if status == 200:\n",
    "    print(f\"Successful S3 get_object response. Status - {status}\")\n",
    "    dependent_df = pd.read_csv(response.get(\"Body\"))\n",
    "else:\n",
    "    print(f\"Unsuccessful S3 get_object response. Status - {status}\")\n",
    "    \n",
    "    \n",
    "dependent_df.columns = dependent_df.columns.str.lower()\n",
    "dependent_df = dependent_df.set_index('person_id_syn')\n",
    "\n",
    "dependent_train_df = dependent_df[(dependent_df.index.isin(train_indexes['person_id_syn']))]\n",
    "dependent_valid_df = dependent_df[~(dependent_df.index.isin(train_indexes['person_id_syn']))]\n",
    "\n",
    "\n",
    "# filename = 'dependent.parquet.gzip'\n",
    "# s3_train_url = 's3://{}/{}/{}'.format(bucket, prefix_train, filename)\n",
    "# s3_valid_url = 's3://{}/{}/{}'.format(bucket, prefix_valid, filename)\n",
    "# dependent_train_df.to_parquet(s3_train_url, compression='gzip')\n",
    "# dependent_valid_df.to_parquet(s3_valid_url, compression='gzip')\n",
    "\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "csv_buffer = StringIO()\n",
    "dependent_train_df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename_dependent = \"dependent.csv\"\n",
    "\n",
    "fe_path = prefix_train + '/' + filename_dependent\n",
    "s3_resource.Object(bucket, fe_path).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "dependent_valid_df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename_dependent = \"dependent.csv\"\n",
    "\n",
    "fe_path = prefix_valid + '/' + filename_dependent\n",
    "s3_resource.Object(bucket, fe_path).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6beb3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving index as parquet files\n",
    "filename = 'index_person_id_syn.parquet.gzip'\n",
    "s3_train_url = 's3://{}/{}/{}'.format(bucket, prefix_train, filename)\n",
    "s3_valid_url = 's3://{}/{}/{}'.format(bucket, prefix_valid, filename)\n",
    "\n",
    "\n",
    "train_indexes.to_parquet(s3_train_url, compression='gzip')\n",
    "valid_indexes.to_parquet(s3_valid_url, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6358d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a5a845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful S3 get_object response. Status - 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'D8NK9S63TCKZH2KD',\n",
       "  'HostId': '1umOdeg3XvUgmlt/ZZp2I9+8MGGIEAGhemOmqx/sNznjDD+ROlU1UlYKm4TBhD+gZ6LQMq3YAbY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '1umOdeg3XvUgmlt/ZZp2I9+8MGGIEAGhemOmqx/sNznjDD+ROlU1UlYKm4TBhD+gZ6LQMq3YAbY=',\n",
       "   'x-amz-request-id': 'D8NK9S63TCKZH2KD',\n",
       "   'date': 'Wed, 16 Nov 2022 19:06:44 GMT',\n",
       "   'x-amz-version-id': '2ddeOMj.1HlO3EIshliV2A8lo_aeZ6SY',\n",
       "   'etag': '\"05365e306463a8d14f695461d04fbcb5\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"05365e306463a8d14f695461d04fbcb5\"',\n",
       " 'VersionId': '2ddeOMj.1HlO3EIshliV2A8lo_aeZ6SY'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit\n",
    "\n",
    "# Get the demo file\n",
    "response = conn.get_object(Bucket=bucket, Key='rawdata/original_raw_files/full_data/Credit.csv')\n",
    "status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "if status == 200:\n",
    "    print(f\"Successful S3 get_object response. Status - {status}\")\n",
    "    credit_df = pd.read_csv(response.get(\"Body\"))\n",
    "else:\n",
    "    print(f\"Unsuccessful S3 get_object response. Status - {status}\")\n",
    "    \n",
    "    \n",
    "credit_df.columns = credit_df.columns.str.lower()\n",
    "credit_df = credit_df.set_index('person_id_syn')\n",
    "# credit_df = credit_df.merge(condition_df, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "credit_train_df = credit_df[(credit_df.index.isin(train_indexes['person_id_syn']))]\n",
    "credit_valid_df = credit_df[~(credit_df.index.isin(train_indexes['person_id_syn']))]\n",
    "\n",
    "\n",
    "# filename = 'credit.parquet.gzip'\n",
    "# s3_train_url = 's3://{}/{}/{}'.format(bucket, prefix_train, filename)\n",
    "# s3_valid_url = 's3://{}/{}/{}'.format(bucket, prefix_valid, filename)\n",
    "# credit_train_df.to_parquet(s3_train_url, compression='gzip')\n",
    "# credit_valid_df.to_parquet(s3_valid_url, compression='gzip')\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "csv_buffer = StringIO()\n",
    "credit_train_df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename_credit = \"credit.csv\"\n",
    "fe_path = prefix_train + '/' + filename_credit\n",
    "s3_resource.Object(bucket, fe_path).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "credit_valid_df.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename_credit = \"credit.csv\"\n",
    "fe_path = prefix_valid + '/' + filename_credit\n",
    "s3_resource.Object(bucket, fe_path).put(Body=csv_buffer.getvalue())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f3913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08b11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee586f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f5133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
